{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load_data import load_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from src.svm import MultiClassKernelSVM\n",
    "from src.kmeans import SphericalKMeans\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr (5000, 3072); Ytr (5000,); Xte (2000, 3072)\n",
      "Xtr (5000, 32, 32, 3); Ytr (5000,); Xte (2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "Xtr_flat, Ytr_flat, Xte_flat = load_data(data_folder, reshape=False)\n",
    "print(f\"Xtr {Xtr_flat.shape}; Ytr {Ytr_flat.shape}; Xte {Xte_flat.shape}\")\n",
    "\n",
    "Xtr, Ytr, Xte = load_data(data_folder, reshape=True)\n",
    "print(f\"Xtr {Xtr.shape}; Ytr {Ytr.shape}; Xte {Xte.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr mean [-2.47982934e-04 -1.74261584e-03 -9.22621259e-05 ...  2.58250453e-03\n",
      "  2.19476255e-03  3.04047441e-03] ; var [0.00167989 0.00118951 0.00118582 ... 0.00124412 0.00126839 0.00177964]\n",
      "Xtr mean [-2.84217094e-18 -7.10542736e-18 -1.84741111e-17 ... -1.84741111e-17\n",
      " -8.52651283e-18 -1.24344979e-17] ; var [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Xtr mean {Xtr_flat.mean(axis=0)} ; var {Xtr_flat.var(axis=0)}\")\n",
    "\n",
    "# should we z-scored the data ?\n",
    "scaler = StandardScaler()\n",
    "Xtr_flat = scaler.fit_transform(Xtr_flat)\n",
    "print(f\"Xtr mean {Xtr_flat.mean(axis=0)} ; var {Xtr_flat.var(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "ntrain = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kernelchallenge.classifiers.svm import rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_svm = MultiClassSVM(num_classes=n_classes, kernel_func=rbf_kernel, c=1)\n",
    "# my_svm.fit(Xtr_flat[:ntrain], Ytr_flat[:ntrain])\n",
    "# pred = my_svm.predict(Xtr_flat[ntrain:])\n",
    "\n",
    "# print(f\"Accuracy {jnp.mean(pred == Ytr_flat[ntrain:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 4.92 seconds\n",
      "Function predict took 43.04 seconds\n",
      "Accuracy 0.14733333885669708\n"
     ]
    }
   ],
   "source": [
    "sigma = jnp.sqrt(Xtr_flat.shape[1])\n",
    "c = 1\n",
    "kernel_func = RBF(sigma=sigma)\n",
    "my_svm = MultiClassKernelSVM(num_classes=n_classes, kernel_func=kernel_func, c=c)\n",
    "my_svm.fit(Xtr_flat[:ntrain], Ytr_flat[:ntrain])\n",
    "pred = my_svm.predict(Xtr_flat[ntrain:])\n",
    "\n",
    "print(f\"Accuracy {jnp.mean(pred == Ytr_flat[ntrain:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 421.93 seconds\n"
     ]
    }
   ],
   "source": [
    "ntrain = Xtr_flat.shape[0]\n",
    "kernel_func = RBF(sigma=sigma)\n",
    "my_svm = MultiClassKernelSVM(num_classes=n_classes, kernel_func=kernel_func, c=c)\n",
    "my_svm.fit(Xtr_flat[:ntrain], Ytr_flat[:ntrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte = scaler.transform(Xte_flat)\n",
    "Yte = my_svm.predict(Xte)\n",
    "Yte = {\"Prediction\": Yte}\n",
    "dataframe = pd.DataFrame(Yte)\n",
    "dataframe.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(f\"{data_folder}/Yte.csv\", index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ON ANOTHER DATASET\n",
    "# from sklearn import datasets\n",
    "# from sklearn import preprocessing\n",
    "# from absl import flags\n",
    "\n",
    "\n",
    "# flags.DEFINE_float(\"tol\", 1e-5, \"Tolerance of solvers.\")\n",
    "# flags.DEFINE_float(\"l2reg\", 1000., \"Regularization parameter. Must be positive.\")\n",
    "# flags.DEFINE_integer(\"num_samples\", 20, \"Size of train set.\")\n",
    "# flags.DEFINE_integer(\"num_features\", 5, \"Features dimension.\")\n",
    "# flags.DEFINE_integer(\"num_classes\", 3, \"Number of classes.\")\n",
    "# flags.DEFINE_bool(\"verbose\", False, \"Verbosity.\")\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# num_samples = 400\n",
    "# num_features = 5\n",
    "# num_classes = 3\n",
    "\n",
    "# X, y = datasets.make_classification(n_samples=num_samples, n_features=num_features,\n",
    "#                                       n_informative=3, n_classes=num_classes, random_state=0)\n",
    "# X = preprocessing.Normalizer().fit_transform(X)\n",
    "# Y = preprocessing.LabelBinarizer().fit_transform(y)\n",
    "# Y = jnp.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 1.88 seconds\n",
      "Function predict took 0.20 seconds\n",
      "Accuracy 0.7899999618530273\n"
     ]
    }
   ],
   "source": [
    "# ntrain = 300\n",
    "# my_svm = MultiClassSVM(num_classes=n_classes, kernel_func=rbf_kernel, c=1)\n",
    "# my_svm.fit(X[:ntrain], y[:ntrain])\n",
    "# pred = my_svm.predict(X[ntrain:])\n",
    "\n",
    "# print(f\"Accuracy {jnp.mean(pred == y[ntrain:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ovelapping_patch_idx(h : int, w:int, patch_size: int =3):\n",
    "        \"\"\"  \"\"\"\n",
    "        xp, yp = jnp.meshgrid(jnp.arange(w-patch_size+1), jnp.arange(h-patch_size+1))\n",
    "        x, y = jnp.meshgrid(jnp.arange(patch_size), jnp.arange(patch_size))\n",
    "        X = x[None, None, ...] + xp[..., None, None]\n",
    "        X = X.reshape(-1, patch_size, patch_size)\n",
    "        Y = y[None, None, ...] + yp[..., None, None]\n",
    "        Y = Y.reshape(-1, patch_size, patch_size)\n",
    "\n",
    "        return (Y, X)\n",
    "\n",
    "def normalize_row(X : jnp.ndarray) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "     norm_rows = jnp.linalg.norm(X, axis=1, ord=2, keepdims=True)\n",
    "     return X / norm_rows, norm_rows\n",
    "\n",
    "def kappa(x : jnp.ndarray, alpha : float):\n",
    "     \"\"\" gaussian function \"\"\"\n",
    "     return jnp.exp(alpha * (x - 1))\n",
    "\n",
    "def linear_gaussian_pooling(map : jnp.ndarray, beta : float = 1, sampling_factor : int = 2):\n",
    "    h, w, c = map.shape\n",
    "    hpool = h // sampling_factor\n",
    "    conv_pool = jnp.zeros((hpool, hpool, c))\n",
    "    z = jnp.stack(jnp.meshgrid(jnp.arange(h), jnp.arange(w), indexing='ij'), axis=2)\n",
    "    for i in range(0, hpool):\n",
    "        for j in range(0, hpool):\n",
    "            pixel = jnp.array([i*sampling_factor, j*sampling_factor])\n",
    "            conv_pool = conv_pool.at[i,j].set(jnp.sum(map * jnp.exp( - beta *  jnp.sum((pixel[None, None, :] - z)**2 , axis=2))[..., None], axis = (0, 1)))\n",
    "\n",
    "    return conv_pool\n",
    "\n",
    "\n",
    "class ConvKN:\n",
    "    \"\"\" CKN Layer \"\"\"\n",
    "\n",
    "    def __init__(self, patch_size:int, out_channels : int, sampling_factor : int = 2,\n",
    "                 n_patch_per_img_for_kmean : int = 10) -> None:\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_idx = None\n",
    "        self.patch_pad_idx = None\n",
    "        self.Z = None\n",
    "        self.out_channels = out_channels\n",
    "        self.sampling_factor = sampling_factor\n",
    "        self.spherical_kmeans = SphericalKMeans(nb_clusters=self.out_channels, max_iter=1000)\n",
    "        self.n_patch_per_img_for_kmean = n_patch_per_img_for_kmean\n",
    "\n",
    "    def extract_patches_2d(self, img : jnp.ndarray, inference : bool = False):\n",
    "        if inference :\n",
    "            if self.patch_pad_idx is None:\n",
    "                h, w, _ = img.shape\n",
    "                self.patch_pad_idx = get_ovelapping_patch_idx(h, w, self.patch_size)\n",
    "            return img[self.patch_pad_idx]\n",
    "        else :\n",
    "            if self.patch_idx is None :\n",
    "                # to do once\n",
    "                h, w, _ = img.shape\n",
    "                self.patch_idx = get_ovelapping_patch_idx(h, w, self.patch_size)\n",
    "\n",
    "            return img[self.patch_idx]\n",
    "    \n",
    "    def train(self, key, input_maps):\n",
    "        \n",
    "        # centering the patch for the layer 0 ?\n",
    "        \n",
    "        # extract random patches \n",
    "        batch_size, _, _, in_channels = input_maps.shape\n",
    "        X = jnp.empty((0, in_channels*self.patch_size**2))\n",
    "        for i in range(batch_size):\n",
    "            patches = self.extract_patches_2d(input_maps[i])\n",
    "            patches = patches.reshape(-1, in_channels*self.patch_size**2)\n",
    "            \n",
    "            # remove constant patches\n",
    "            non_cst_idx = jnp.any(patches != patches[:, [0]], axis=1) # to remove\n",
    "            n_patch = min(non_cst_idx.sum(), self.n_patch_per_img_for_kmean)\n",
    "            key, _ = jax.random.split(key)\n",
    "            X = jnp.vstack((X, \n",
    "                           jax.random.choice(key, patches[non_cst_idx], shape=(n_patch,), replace=False, axis=0))\n",
    "            )\n",
    "            \n",
    "        X = jax.random.permutation(key, X, axis=0)\n",
    "        # normalize row applying kmeans\n",
    "        X, _ = normalize_row(X) \n",
    "        self.Z, _ = self.spherical_kmeans.fit(X, init_centroids=self.Z) # centroids are normalized\n",
    "        \n",
    "        # compute linear weights\n",
    "        mat = kappa(self.Z.dot(self.Z.T), alpha = 1/ .5**2) # out_channels x out_channels\n",
    "        D, U = jnp.linalg.eigh(mat)\n",
    "        inv_sqrt_D = jnp.diag((D + 1e-9) ** (-0.5))\n",
    "        self.W = U.dot(inv_sqrt_D.dot(U.T))         \n",
    "        \n",
    "\n",
    "    def __call__(self, input_maps : jnp.ndarray):\n",
    "        \"\"\"\n",
    "        Suppose images are squarred\n",
    "        :param input_maps : array of size (B, H, W, C) B is batch size, C is channel size (e.g. 3)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.Z is None:\n",
    "             raise Warning('Filters Z have to be initialized or learned. Call .train() befor evaluating model')\n",
    "\n",
    "        batch_size, h, w, in_channels = input_maps.shape\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # add padding, so that there is a patch for each pixel in input map\n",
    "            pad = (self.patch_size - 1)\n",
    "            p = pad // 2\n",
    "            image = jnp.zeros((h+pad, w+pad, in_channels))\n",
    "            image = image.at[p:p+h, p:p+w, :].set(input_maps[i])\n",
    "\n",
    "            patches = self.extract_patches_2d(image, inference=True)\n",
    "            patches = patches.reshape(-1, in_channels*self.patch_size**2)\n",
    "\n",
    "            normalized_x, norm_x = normalize_row(patches)\n",
    "    \n",
    "            out_map = norm_x * kappa( normalized_x.dot(self.Z.T), alpha=1/(.25)).dot(self.W)\n",
    "            out_map = out_map.reshape(h, w, self.out_channels)\n",
    "            # linear pooling\n",
    "            beta = jnp.sqrt(1 / (h*self.sampling_factor)) # jnp.sqrt(jnp.sqrt(2)/self.sampling_factor)\n",
    "\n",
    "            conv_pool = linear_gaussian_pooling(out_map, beta=beta,\n",
    "                                                sampling_factor=self.sampling_factor)\n",
    "            if i == 0:\n",
    "                out_maps = conv_pool[None, ...]\n",
    "            else :\n",
    "                out_maps = jnp.vstack((out_maps,\n",
    "                                    conv_pool[None, ...]))\n",
    "            \n",
    "        return out_maps\n",
    "    \n",
    "\n",
    "class ModelCKN:\n",
    "    def __init__(self, patch_sizes : list,\n",
    "                 out_channels : list,\n",
    "                 subsampling_factors : list,\n",
    "                 n_patch_per_img_for_kmean : int = 20):\n",
    "        self.n_layers = len(out_channels)\n",
    "        self.layers = []\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers.append( ConvKN(patch_size=patch_sizes[i], \n",
    "                                       out_channels=out_channels[i],\n",
    "                                       sampling_factor=subsampling_factors[i],\n",
    "                                       n_patch_per_img_for_kmean = n_patch_per_img_for_kmean)\n",
    "                                       )\n",
    "            \n",
    "    def train(self, key, input_maps):\n",
    "        keys = jax.random.split(key, self.n_layers)\n",
    "        input_maps_layer = input_maps.copy()\n",
    "        for i in range(self.n_layers):\n",
    "            \n",
    "            self.layers[i].train(keys[i], input_maps_layer)\n",
    "            input_maps_layer = self.layers[i](input_maps_layer)\n",
    "\n",
    "    def __call__(self, input_maps):\n",
    "    \n",
    "        for i in range(self.n_layers):\n",
    "            input_maps = self.layers[i](input_maps)\n",
    "\n",
    "        return input_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr (5000, 32, 32, 3); Ytr (5000,); Xte (2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "Xtr, Ytr, Xte = load_data(data_folder, reshape=True)\n",
    "print(f\"Xtr {Xtr.shape}; Ytr {Ytr.shape}; Xte {Xte.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.4883\n",
      "End of main loop\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(6)\n",
    "model = ConvKN(patch_size=3, out_channels=4, sampling_factor=2, n_patch_per_img_for_kmean=20)\n",
    "model.train(key, Xtr[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(Xtr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([nan], dtype=float32)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.unique(out.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.7265\n",
      "Spherical K means at iter 20 :  mean cosine similarity 0.7293\n",
      "Spherical K means at iter 30 :  mean cosine similarity 0.7302\n",
      "Spherical K means at iter 40 :  mean cosine similarity 0.7305\n",
      "Spherical K means at iter 50 :  mean cosine similarity 0.7306\n",
      "End of main loop\n",
      "Spherical Kmean main loop starts\n",
      "End of main loop\n"
     ]
    }
   ],
   "source": [
    "myCKN = ModelCKN(patch_sizes=[3, 2],\n",
    "                 out_channels=[100, 200],\n",
    "                 subsampling_factors=[2, 4],\n",
    "                 n_patch_per_img_for_kmean=10)\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "myCKN.train(key, Xtr[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = myCKN(Xtr[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myckn.pkl', 'wb') as f:\n",
    "    pickle.dump(myCKN, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-score output\n",
    "# X = out - out.mean(axis=1)\n",
    "# X = X / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
