{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load_data import load_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from src.svm import MultiClassKernelSVM\n",
    "from src.kmeans import SphericalKMeans\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from src.kernels import RBF\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr (5000, 3072); Ytr (5000,); Xte (2000, 3072)\n",
      "Xtr (5000, 32, 32, 3); Ytr (5000,); Xte (2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "Xtr_flat, Ytr_flat, Xte_flat = load_data(data_folder, reshape=False)\n",
    "print(f\"Xtr {Xtr_flat.shape}; Ytr {Ytr_flat.shape}; Xte {Xte_flat.shape}\")\n",
    "\n",
    "Xtr, Ytr, Xte = load_data(data_folder, reshape=True)\n",
    "print(f\"Xtr {Xtr.shape}; Ytr {Ytr.shape}; Xte {Xte.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr mean [-2.47982934e-04 -1.74261584e-03 -9.22621259e-05 ...  2.58250453e-03\n",
      "  2.19476255e-03  3.04047441e-03] ; var [0.00167989 0.00118951 0.00118582 ... 0.00124412 0.00126839 0.00177964]\n",
      "Xtr mean [-2.84217094e-18 -7.10542736e-18 -1.84741111e-17 ... -1.84741111e-17\n",
      " -8.52651283e-18 -1.24344979e-17] ; var [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Xtr mean {Xtr_flat.mean(axis=0)} ; var {Xtr_flat.var(axis=0)}\")\n",
    "\n",
    "# should we z-scored the data ?\n",
    "scaler = StandardScaler()\n",
    "Xtr_flat = scaler.fit_transform(Xtr_flat)\n",
    "print(f\"Xtr mean {Xtr_flat.mean(axis=0)} ; var {Xtr_flat.var(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "ntrain = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kernelchallenge.classifiers.svm import rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_svm = MultiClassSVM(num_classes=n_classes, kernel_func=rbf_kernel, c=1)\n",
    "# my_svm.fit(Xtr_flat[:ntrain], Ytr_flat[:ntrain])\n",
    "# pred = my_svm.predict(Xtr_flat[ntrain:])\n",
    "\n",
    "# print(f\"Accuracy {jnp.mean(pred == Ytr_flat[ntrain:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 4.92 seconds\n",
      "Function predict took 43.04 seconds\n",
      "Accuracy 0.14733333885669708\n"
     ]
    }
   ],
   "source": [
    "sigma = jnp.sqrt(Xtr_flat.shape[1])\n",
    "c = 1\n",
    "kernel_func = RBF(sigma=sigma)\n",
    "my_svm = MultiClassKernelSVM(num_classes=n_classes, kernel_func=kernel_func, c=c)\n",
    "my_svm.fit(Xtr_flat[:ntrain], Ytr_flat[:ntrain])\n",
    "pred = my_svm.predict(Xtr_flat[ntrain:])\n",
    "\n",
    "print(f\"Accuracy {jnp.mean(pred == Ytr_flat[ntrain:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 421.93 seconds\n"
     ]
    }
   ],
   "source": [
    "ntrain = Xtr_flat.shape[0]\n",
    "kernel_func = RBF(sigma=sigma)\n",
    "my_svm = MultiClassKernelSVM(num_classes=n_classes, kernel_func=kernel_func, c=c)\n",
    "my_svm.fit(Xtr_flat[:ntrain], Ytr_flat[:ntrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte = scaler.transform(Xte_flat)\n",
    "Yte = my_svm.predict(Xte)\n",
    "Yte = {\"Prediction\": Yte}\n",
    "dataframe = pd.DataFrame(Yte)\n",
    "dataframe.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(f\"{data_folder}/Yte.csv\", index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ON ANOTHER DATASET\n",
    "# from sklearn import datasets\n",
    "# from sklearn import preprocessing\n",
    "# from absl import flags\n",
    "\n",
    "\n",
    "# flags.DEFINE_float(\"tol\", 1e-5, \"Tolerance of solvers.\")\n",
    "# flags.DEFINE_float(\"l2reg\", 1000., \"Regularization parameter. Must be positive.\")\n",
    "# flags.DEFINE_integer(\"num_samples\", 20, \"Size of train set.\")\n",
    "# flags.DEFINE_integer(\"num_features\", 5, \"Features dimension.\")\n",
    "# flags.DEFINE_integer(\"num_classes\", 3, \"Number of classes.\")\n",
    "# flags.DEFINE_bool(\"verbose\", False, \"Verbosity.\")\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# num_samples = 400\n",
    "# num_features = 5\n",
    "# num_classes = 3\n",
    "\n",
    "# X, y = datasets.make_classification(n_samples=num_samples, n_features=num_features,\n",
    "#                                       n_informative=3, n_classes=num_classes, random_state=0)\n",
    "# X = preprocessing.Normalizer().fit_transform(X)\n",
    "# Y = preprocessing.LabelBinarizer().fit_transform(y)\n",
    "# Y = jnp.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 1.88 seconds\n",
      "Function predict took 0.20 seconds\n",
      "Accuracy 0.7899999618530273\n"
     ]
    }
   ],
   "source": [
    "# ntrain = 300\n",
    "# my_svm = MultiClassSVM(num_classes=n_classes, kernel_func=rbf_kernel, c=1)\n",
    "# my_svm.fit(X[:ntrain], y[:ntrain])\n",
    "# pred = my_svm.predict(X[ntrain:])\n",
    "\n",
    "# print(f\"Accuracy {jnp.mean(pred == y[ntrain:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.8160863  -0.48262316  0.33988908]\n",
      "[1.8160863 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "f = jax.random.normal(key, (3,))\n",
    "print(f)\n",
    "f = f.at[f<1].set(0)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ovelapping_patch_idx(h : int, w:int, patch_size: int =3):\n",
    "        \"\"\"  \"\"\"\n",
    "        xp, yp = jnp.meshgrid(jnp.arange(w-patch_size+1), jnp.arange(h-patch_size+1))\n",
    "        x, y = jnp.meshgrid(jnp.arange(patch_size), jnp.arange(patch_size))\n",
    "        X = x[None, None, ...] + xp[..., None, None]\n",
    "        X = X.reshape(-1, patch_size, patch_size)\n",
    "        Y = y[None, None, ...] + yp[..., None, None]\n",
    "        Y = Y.reshape(-1, patch_size, patch_size)\n",
    "\n",
    "        return (Y, X)\n",
    "\n",
    "def normalize_row(X : jnp.ndarray) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "     norm_rows = jnp.linalg.norm(X, axis=1, ord=2, keepdims=True)\n",
    "     return X / (norm_rows + 1e-5), norm_rows\n",
    "\n",
    "def kappa(x : jnp.ndarray, alpha : float):\n",
    "     \"\"\" gaussian function \"\"\"\n",
    "     return jnp.exp(alpha * (x - 1))\n",
    "\n",
    "def linear_gaussian_pooling(map : jnp.ndarray, beta : float = 1, sampling_factor : int = 2):\n",
    "    h, w, c = map.shape\n",
    "    hpool = h // sampling_factor\n",
    "    conv_pool = jnp.zeros((hpool, hpool, c))\n",
    "    z = jnp.stack(jnp.meshgrid(jnp.arange(h), jnp.arange(w), indexing='ij'), axis=2)\n",
    "    for i in range(0, hpool):\n",
    "        for j in range(0, hpool):\n",
    "            pixel = jnp.array([i*sampling_factor, j*sampling_factor])\n",
    "            conv_pool = conv_pool.at[i,j].set(jnp.sum(map * jnp.exp( - beta *  jnp.sum((pixel[None, None, :] - z)**2 , axis=2))[..., None], axis = (0, 1)))\n",
    "\n",
    "    return conv_pool\n",
    "\n",
    "\n",
    "class ConvKN:\n",
    "    \"\"\" CKN Layer \"\"\"\n",
    "\n",
    "    def __init__(self, patch_size:int, out_channels : int, sampling_factor : int = 2,\n",
    "                 n_patch_per_img_for_kmean : int = 10) -> None:\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_idx = None\n",
    "        self.patch_pad_idx = None\n",
    "        self.Z = None\n",
    "        self.out_channels = out_channels\n",
    "        self.sampling_factor = sampling_factor\n",
    "        self.spherical_kmeans = SphericalKMeans(nb_clusters=self.out_channels, max_iter=1000)\n",
    "        self.n_patch_per_img_for_kmean = n_patch_per_img_for_kmean\n",
    "\n",
    "    def extract_patches_2d(self, img : jnp.ndarray, inference : bool = False):\n",
    "        if inference :\n",
    "            if self.patch_pad_idx is None:\n",
    "                h, w, _ = img.shape\n",
    "                self.patch_pad_idx = get_ovelapping_patch_idx(h, w, self.patch_size)\n",
    "            return img[self.patch_pad_idx]\n",
    "        else :\n",
    "            if self.patch_idx is None :\n",
    "                # to do once\n",
    "                h, w, _ = img.shape\n",
    "                self.patch_idx = get_ovelapping_patch_idx(h, w, self.patch_size)\n",
    "\n",
    "            return img[self.patch_idx]\n",
    "    \n",
    "    def train(self, key, input_maps):\n",
    "        \n",
    "        # centering the patch for the layer 0 ?\n",
    "        \n",
    "        # extract random patches \n",
    "        batch_size, _, _, in_channels = input_maps.shape\n",
    "        X = jnp.empty((0, in_channels*self.patch_size**2))\n",
    "        for i in range(batch_size):\n",
    "            patches = self.extract_patches_2d(input_maps[i])\n",
    "            patches = patches.reshape(-1, in_channels*self.patch_size**2)\n",
    "            \n",
    "            # remove constant patches\n",
    "            non_cst_idx = jnp.any(patches != patches[:, [0]], axis=1) # to remove\n",
    "            n_patch = min(non_cst_idx.sum(), self.n_patch_per_img_for_kmean)\n",
    "            # n_patch = min(patches.shape[0], self.n_patch_per_img_for_kmean)\n",
    "            key, _ = jax.random.split(key)\n",
    "            X = jnp.vstack((X, \n",
    "                           jax.random.choice(key, patches[non_cst_idx], shape=(n_patch,), replace=False, axis=0))\n",
    "            )\n",
    "            \n",
    "        X = jax.random.permutation(key, X, axis=0)\n",
    "        # normalize row applying kmeans\n",
    "        X, _ = normalize_row(X) \n",
    "        print(f'For training kmeans, X shape {X.shape}')\n",
    "        self.Z, _ = self.spherical_kmeans.fit(X, init_centroids=self.Z) # centroids are normalized\n",
    "        \n",
    "        # compute linear weights\n",
    "        mat = kappa(self.Z.dot(self.Z.T), alpha = 1/ .5**2) # out_channels x out_channels\n",
    "        D, U = jnp.linalg.eigh(mat)\n",
    "        D = D.at[D<1e-6].set(1e-6)\n",
    "        inv_sqrt_D = jnp.diag(D  ** (-0.5))\n",
    "        self.W = U.dot(inv_sqrt_D.dot(U.T))         \n",
    "        \n",
    "\n",
    "    def __call__(self, input_maps : jnp.ndarray):\n",
    "        \"\"\"\n",
    "        Suppose images are squarred\n",
    "        :param input_maps : array of size (B, H, W, C) B is batch size, C is channel size (e.g. 3)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.Z is None:\n",
    "             raise Warning('Filters Z have to be initialized or learned. Call .train() befor evaluating model')\n",
    "\n",
    "        batch_size, h, w, in_channels = input_maps.shape\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # add padding, so that there is a patch for each pixel in input map\n",
    "            pad = (self.patch_size - 1)\n",
    "            p = pad // 2\n",
    "            image = jnp.zeros((h+pad, w+pad, in_channels))\n",
    "            image = image.at[p:p+h, p:p+w, :].set(input_maps[i])\n",
    "\n",
    "            patches = self.extract_patches_2d(image, inference=True)\n",
    "            patches = patches.reshape(-1, in_channels*self.patch_size**2)\n",
    "\n",
    "            normalized_x, norm_x = normalize_row(patches)\n",
    "    \n",
    "            out_map = norm_x * kappa( normalized_x.dot(self.Z.T), alpha=1/(.25)).dot(self.W)\n",
    "            out_map = out_map.reshape(h, w, self.out_channels)\n",
    "            # linear pooling\n",
    "            beta = jnp.square(jnp.sqrt(2)/self.sampling_factor) # jnp.square(1 / (h*self.sampling_factor))\n",
    "\n",
    "            conv_pool = linear_gaussian_pooling(out_map, beta=beta,\n",
    "                                                sampling_factor=self.sampling_factor)\n",
    "            if i == 0:\n",
    "                out_maps = conv_pool[None, ...]\n",
    "            else :\n",
    "                out_maps = jnp.vstack((out_maps,\n",
    "                                    conv_pool[None, ...]))\n",
    "                \n",
    "            if jnp.isnan(out_maps).any():\n",
    "                print('i', i)\n",
    "                raise Warning(f'Output map has {jnp.isnan(out_maps).sum()} NaN values')\n",
    "            \n",
    "        return out_maps\n",
    "    \n",
    "\n",
    "class ModelCKN:\n",
    "    def __init__(self, patch_sizes : list,\n",
    "                 out_channels : list,\n",
    "                 subsampling_factors : list,\n",
    "                 n_patch_per_img_for_kmean : int = 20):\n",
    "        self.n_layers = len(out_channels)\n",
    "        self.layers = []\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers.append( ConvKN(patch_size=patch_sizes[i], \n",
    "                                       out_channels=out_channels[i],\n",
    "                                       sampling_factor=subsampling_factors[i],\n",
    "                                       n_patch_per_img_for_kmean = n_patch_per_img_for_kmean)\n",
    "                                       )\n",
    "            \n",
    "    def train(self, key, input_maps, batch_size=2000):\n",
    "        keys = [key]\n",
    "        \n",
    "\n",
    "        N = input_maps.shape[0]\n",
    "        train_idx = jax.random.choice(key, jnp.arange(N), (N//batch_size, batch_size), replace=False)\n",
    "        for b in range(len(train_idx)):\n",
    "            input_maps_layer = input_maps[train_idx[b]]\n",
    "            keys = jax.random.split(keys[-1], self.n_layers)\n",
    "            print('b', b)\n",
    "            for i in range(self.n_layers):\n",
    "                self.layers[i].train(keys[i], input_maps_layer)\n",
    "                input_maps_layer = self.layers[i](input_maps_layer)\n",
    "                print(f'Layer {i}: out max {input_maps_layer.max()} out min {input_maps_layer.min()} Z max {self.layers[i].Z.max()} W max {self.layers[i].W.max()}')\n",
    "                print(f'Output map shape {input_maps_layer.shape}')\n",
    "\n",
    "    def __call__(self, input_maps):\n",
    "    \n",
    "        for i in range(self.n_layers):\n",
    "            input_maps = self.layers[i](input_maps)\n",
    "\n",
    "        return input_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr (5000, 32, 32, 3); Ytr (5000,); Xte (2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "Xtr, Ytr, Xte = load_data(data_folder, reshape=True)\n",
    "print(f\"Xtr {Xtr.shape}; Ytr {Ytr.shape}; Xte {Xte.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr mean -2.257679460049289e-11 ; var 1.0\n"
     ]
    }
   ],
   "source": [
    "# should we z-scored the data ?\n",
    "# Xtr = Xtr - Xtr.mean(axis=0)\n",
    "# Xtr = Xtr/jnp.sqrt(jnp.mean(Xtr**2, axis=0, keepdims=True))\n",
    "# print(f\"Xtr mean {Xtr.mean(axis=0).mean()} ; var {Xtr.var(axis=0).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(6)\n",
    "model = ConvKN(patch_size=2, out_channels=64, sampling_factor=2, n_patch_per_img_for_kmean=20)\n",
    "model.train(key, Xtr[:20])\n",
    "out = model(Xtr[:20])\n",
    "jnp.isnan(out).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 0\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8253\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8296\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8302\n",
      "Spherical K means at iter 20 :  mean cosine similarity 0.8305\n",
      "Spherical K means at iter 25 :  mean cosine similarity 0.8306\n",
      "End of main loop\n",
      "Layer 0: out max 0.744384229183197 out min -0.03800946846604347 Z max 0.7713486552238464 W max 1.5558363199234009\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8389\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8399\n",
      "End of main loop\n",
      "Layer 1: out max 2.026366949081421 out min -0.10908164829015732 Z max 0.4979182779788971 W max 2.0815765857696533\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 1\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8292\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8326\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8332\n",
      "End of main loop\n",
      "Layer 0: out max 0.7428005337715149 out min -0.019860610365867615 Z max 0.7603052854537964 W max 1.5128344297409058\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [113]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8374\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8386\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8387\n",
      "End of main loop\n",
      "Layer 1: out max 2.2245543003082275 out min -0.13089023530483246 Z max 0.5363526940345764 W max 2.2674367427825928\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 2\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8313\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8327\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8330\n",
      "Spherical K means at iter 20 :  mean cosine similarity 0.8334\n",
      "Spherical K means at iter 25 :  mean cosine similarity 0.8337\n",
      "End of main loop\n",
      "Layer 0: out max 0.8313519954681396 out min -0.028192143887281418 Z max 0.7188304662704468 W max 1.6844255924224854\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [ 94  97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8363\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8376\n",
      "End of main loop\n",
      "Layer 1: out max 2.5647528171539307 out min -0.08999520540237427 Z max 0.5600746273994446 W max 2.038193941116333\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 3\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8312\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8329\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8333\n",
      "End of main loop\n",
      "Layer 0: out max 0.7544983625411987 out min -0.02702806517481804 Z max 0.6797634959220886 W max 1.5201925039291382\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [ 94  97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8328\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8337\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8338\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [ 97 115]\n",
      "End of main loop\n",
      "Layer 1: out max 1.9734022617340088 out min -0.0973096489906311 Z max 0.5462814569473267 W max 666.8921508789062\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 4\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8283\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8305\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8308\n",
      "End of main loop\n",
      "Layer 0: out max 0.8193504214286804 out min -0.028607426211237907 Z max 0.7802867293357849 W max 1.5799113512039185\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [ 97 115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8353\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8360\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "End of main loop\n",
      "Layer 1: out max 2.349839210510254 out min -0.1679595559835434 Z max 0.6273203492164612 W max 500.451904296875\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 5\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8249\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8263\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8266\n",
      "End of main loop\n",
      "Layer 0: out max 1.108497142791748 out min -0.036907196044921875 Z max 0.750748872756958 W max 1.5667201280593872\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8387\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8395\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8396\n",
      "End of main loop\n",
      "Layer 1: out max 2.062453269958496 out min -0.11038301885128021 Z max 0.5307837724685669 W max 500.4019470214844\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 6\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8302\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8317\n",
      "End of main loop\n",
      "Layer 0: out max 0.8212689757347107 out min -0.029885703697800636 Z max 0.6723723411560059 W max 1.6317236423492432\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [ 18  69 115]\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8375\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8385\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [ 69 115]\n",
      "End of main loop\n",
      "Layer 1: out max 2.1050820350646973 out min -0.194760262966156 Z max 0.5500529408454895 W max 666.9078369140625\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 7\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8333\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8347\n",
      "End of main loop\n",
      "Layer 0: out max 0.8124961256980896 out min -0.03445708751678467 Z max 0.7209783792495728 W max 1.7025365829467773\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "empty cluster [ 69 115]\n",
      "empty cluster [115]\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8386\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8394\n",
      "End of main loop\n",
      "Layer 1: out max 2.2756142616271973 out min -0.11156796663999557 Z max 0.4994979202747345 W max 2.416684627532959\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 8\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8315\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8331\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8338\n",
      "End of main loop\n",
      "Layer 0: out max 0.7479902505874634 out min -0.03257736191153526 Z max 0.7267603874206543 W max 1.6540523767471313\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8368\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8375\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8376\n",
      "End of main loop\n",
      "Layer 1: out max 2.0679664611816406 out min -0.13023826479911804 Z max 0.5020111799240112 W max 2.194486379623413\n",
      "Output map shape (100, 8, 8, 128)\n",
      "b 9\n",
      "For training kmeans, X shape (2000, 12)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8301\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8322\n",
      "Spherical K means at iter 15 :  mean cosine similarity 0.8326\n",
      "End of main loop\n",
      "Layer 0: out max 0.7186782956123352 out min -0.030795831233263016 Z max 0.750592827796936 W max 1.6867717504501343\n",
      "Output map shape (100, 16, 16, 64)\n",
      "For training kmeans, X shape (2000, 256)\n",
      "Spherical Kmean main loop starts\n",
      "Spherical K means at iter 5 :  mean cosine similarity 0.8382\n",
      "Spherical K means at iter 10 :  mean cosine similarity 0.8389\n",
      "End of main loop\n",
      "Layer 1: out max 2.0635569095611572 out min -0.1473982036113739 Z max 0.5837286710739136 W max 2.013417959213257\n",
      "Output map shape (100, 8, 8, 128)\n",
      "Training myCKN took 1.33e+03 s \n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(9)\n",
    "myCKN = ModelCKN(patch_sizes=[2, 2],\n",
    "                 out_channels=[64, 128],\n",
    "                 subsampling_factors=[2, 2],\n",
    "                 n_patch_per_img_for_kmean=20)\n",
    "key = jax.random.PRNGKey(0)\n",
    "t0 = time.time()\n",
    "myCKN.train(key, Xtr[:4000], batch_size=1000)\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Training myCKN took {(t1-t0)/60:.1} min \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myckn1.pkl', 'wb') as f:\n",
    "    pickle.dump(myCKN, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "out = myCKN(Xtr[:4000])\n",
    "t1 = time.time()\n",
    "print(out.min(), out.max())\n",
    "print(f'Evaluate myCKN took {(t1-t0)/60:.1} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8, 8, 128)\n",
      "(1000, 8192)\n",
      "Input shape (1000, 8192)\n"
     ]
    }
   ],
   "source": [
    "# z-score output\n",
    "print(out.shape)\n",
    "out = out.reshape(out.shape[0], -1)\n",
    "print(out.shape)\n",
    "X = out - out.mean(axis=0)[None, :]\n",
    "X = X / jnp.sqrt( jnp.mean( X**2, axis=0) )[None, :]\n",
    "print('Input shape', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 10.62 seconds\n",
      "Function predict took 0.48 seconds\n",
      "Acc 0.47\n"
     ]
    }
   ],
   "source": [
    "ntrain = 900\n",
    "kernel_func = RBF(sigma=jnp.sqrt(X.shape[1]))\n",
    "my_svm = MultiClassKernelSVM(num_classes=10, kernel_func=kernel_func, c=1)\n",
    "my_svm.fit(X[:ntrain], Ytr[:ntrain])\n",
    "preds = my_svm.predict(X[ntrain:])\n",
    "\n",
    "print('Acc', jnp.mean(preds == Ytr[ntrain:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
