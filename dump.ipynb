{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import numbers\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from utils.utils_fast import conv2\n",
    "import pickle\n",
    "import utils.load_data import load_data\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_pred(y_pred, outpath=\"output/\"):\n",
    "    ids = np.arange(1, 2001, dtype=int)\n",
    "    arr = np.hstack((ids.reshape(-1, 1), y_pred.reshape(-1, 1)))\n",
    "    arr = arr.astype(int)\n",
    "    np.savetxt(\n",
    "        outpath + \"Yte.csv\",\n",
    "        arr,\n",
    "        header=\"Id,Prediction\",\n",
    "        fmt=\"%d,%d\",\n",
    "        delimiter=\",\",\n",
    "        comments=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def reshape(images, sx=32, n_channels=3):\n",
    "    return images.reshape((-1, n_channels, sx, sx)).swapaxes(1, 2).swapaxes(2, 3)\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"visualize image of given vec: 1 x 3072\"\"\"\n",
    "    if img.ndim < 3:\n",
    "        print(\"ok\")\n",
    "        img = img.reshape((32, 32, 3), order=\"F\")\n",
    "        img = img.swapaxes(0, 1)\n",
    "    for i in range(3):\n",
    "        minval = img[:, :, i].min()\n",
    "        maxval = img[:, :, i].max()\n",
    "        if minval != maxval:\n",
    "            img[:, :, i] -= minval\n",
    "            img[:, :, i] *= 1.0 / (maxval - minval)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def distribution_y(filepath=\"data/\"):\n",
    "    y = np.genfromtxt(filepath + \"Ytr.csv\", delimiter=\",\", skip_header=1, dtype=int)[\n",
    "        :, -1\n",
    "    ]\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(y)\n",
    "    vmin = y.min()\n",
    "    vmax = y.max()\n",
    "    plt.hist(y, bins=np.arange(vmin - 0.5, vmax + 1.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_random_state(seed):\n",
    "    \"\"\"Turn seed into a np.random.RandomState instance\n",
    "    If seed is None, return the RandomState singleton used by np.random.\n",
    "    If seed is an int, return a new RandomState instance seeded with seed.\n",
    "    If seed is already a RandomState instance, return it.\n",
    "    Otherwise raise ValueError.\n",
    "    \"\"\"\n",
    "    if seed is None or seed is np.random:\n",
    "        return np.random.mtrand._rand\n",
    "    if isinstance(seed, (numbers.Integral, np.integer)):\n",
    "        return np.random.RandomState(seed)\n",
    "    if isinstance(seed, np.random.RandomState):\n",
    "        return seed\n",
    "    raise ValueError(\n",
    "        \"%r cannot be used to seed a numpy.random.RandomState\" \" instance\" % seed\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_patches_2d(image, patch_size, step=1):\n",
    "    \"\"\"image : nx x ny x n_channels\n",
    "    output: n_patches x patch_size x patch_size x n_channels\n",
    "    \"\"\"\n",
    "    n_channels = image.shape[-1]\n",
    "    patches = extract_patches(image, (patch_size, patch_size, n_channels), step)\n",
    "    return patches.reshape(-1, patch_size, patch_size, n_channels)\n",
    "\n",
    "\n",
    "def extract_patches(arr, patch_shape, extraction_step):\n",
    "    if isinstance(extraction_step, int):\n",
    "        extraction_step = tuple([extraction_step] * arr.ndim)\n",
    "    patch_strides = arr.strides\n",
    "    slices = tuple(slice(None, None, st) for st in extraction_step)\n",
    "    # print(slices, type(arr), arr)\n",
    "    # slices\n",
    "    indexing_strides = arr[slices].strides\n",
    "\n",
    "    patch_indices_shape = (\n",
    "        (np.array(arr.shape) - np.array(patch_shape)) // np.array(extraction_step)\n",
    "    ) + 1\n",
    "\n",
    "    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n",
    "    strides = tuple(list(indexing_strides) + list(patch_strides))\n",
    "\n",
    "    patches = as_strided(arr, shape=shape, strides=strides)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def centering_patch(patch):\n",
    "    return patch - np.mean(patch, axis=(1, 2), keepdims=1)\n",
    "\n",
    "\n",
    "def shape_patch(patch, threshold=1e-6):\n",
    "    \"\"\"patch: n_patches x size x size x n_channels\n",
    "    output: n_patches x (size^2-1)n_channels\n",
    "    \"\"\"\n",
    "    n_channels = patch.shape[-1]\n",
    "    patch = patch.reshape((patch.shape[0], -1, patch.shape[-1]))\n",
    "    center = int(patch.shape[1] // 2)\n",
    "    patch = patch - patch[:, [center], :]\n",
    "    patch = np.delete(patch, center, 1)  # remove center\n",
    "    patch = patch.reshape((patch.shape[0], -1))\n",
    "    # rho = np.linalg.norm(patch, axis=1)\n",
    "    # rho[rho<threshold] = 0\n",
    "    # # binarize the difference\n",
    "    # cond = patch > 0\n",
    "    # non_cond = patch <= 0\n",
    "    # patch[cond] = 1.0\n",
    "    # patch[non_cond] = 0.0\n",
    "    return patch\n",
    "\n",
    "\n",
    "def normalize_row(X, norm=\"l2\", threshold=1e-5, return_norm=False):\n",
    "    if norm == \"l2\":\n",
    "        norms = np.linalg.norm(X, axis=1)\n",
    "        norms[norms < threshold] = threshold\n",
    "        X /= norms[:, np.newaxis]\n",
    "    if return_norm:\n",
    "        return X, norms\n",
    "    return X\n",
    "\n",
    "\n",
    "def kmeans(X, k, max_iter=1000, init=None):\n",
    "    \"\"\"normal kmeans\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    if init is None:\n",
    "        perm = np.random.choice(np.arange(n_samples), k)\n",
    "        centroids = X[perm]\n",
    "\n",
    "    norm2 = np.linalg.norm(X, axis=1, keepdims=1) ** 2\n",
    "    prev_obj = np.inf\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        dist2 = (\n",
    "            np.linalg.norm(centroids, axis=1) ** 2\n",
    "            - 2.0 * np.dot(X, centroids.T)\n",
    "            + norm2\n",
    "        )\n",
    "        assign = np.argmin(dist2, axis=1)\n",
    "        obj = dist2[np.unravel_index(assign, dist2.shape)].mean()\n",
    "        # print dist.shape\n",
    "        if (n_iter + 1) % 10 == 0:\n",
    "            print((\"kmeans iter %d, objective: %f\" % (n_iter + 1, obj)))\n",
    "\n",
    "        for j in range(k):\n",
    "            Xj = X[assign == j]\n",
    "            if Xj.shape[0] == 0:\n",
    "                centroids[j] = X[np.random.randint(n_samples)]\n",
    "            else:\n",
    "                centroids[j] = np.mean(Xj, axis=0)\n",
    "\n",
    "        if np.abs(prev_obj - obj) / (np.abs(obj) + 1e-20) < 1e-8:\n",
    "            break\n",
    "        prev_obj = obj\n",
    "\n",
    "        # stop criteria\n",
    "    return centroids, assign\n",
    "\n",
    "\n",
    "def spherical_kmeans(X, k, max_iter=1000, init=None):\n",
    "    \"\"\"X: n x d points with unit-norm\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    if init is None:\n",
    "        perm = np.random.choice(np.arange(n_samples), k)\n",
    "        centroids = X[perm]\n",
    "\n",
    "    prev_obj = np.inf\n",
    "    for n_iter in range(max_iter):\n",
    "        cos_sim = np.dot(X, centroids.T)\n",
    "        assign = np.argmax(cos_sim, axis=1)\n",
    "        obj = cos_sim[np.unravel_index(assign, cos_sim.shape)].mean()\n",
    "\n",
    "        if (n_iter + 1) % 10 == 0:\n",
    "            print((\"spherical kmeans iter %d, objective: %f\" % (n_iter + 1, obj)))\n",
    "\n",
    "        for j in range(k):\n",
    "            Xj = X[assign == j]\n",
    "            if Xj.shape[0] == 0:\n",
    "                centroids[j] = X[np.random.randint(n_samples)]\n",
    "            else:\n",
    "                centroids[j] = np.sum(Xj, axis=0)\n",
    "                norm = np.linalg.norm(centroids[j])\n",
    "                centroids[j] /= norm\n",
    "        if np.abs(prev_obj - obj) / (np.abs(obj) + 1e-20) < 1e-8:\n",
    "            break\n",
    "        prev_obj = obj\n",
    "\n",
    "    return centroids, assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_1d(shape, sigma):\n",
    "    m = (shape - 1.0) / 2.0\n",
    "    filt = np.arange(-m, m + 1)\n",
    "    filt = np.exp(-np.square(filt) / (2.0 * sigma**2))\n",
    "    return filt / np.sum(filt)\n",
    "\n",
    "\n",
    "def conv2_gaussian(in1, shape, sigma=0.5):\n",
    "    g_filter = gaussian_filter_1d(shape, sigma)\n",
    "    g_filter = np.outer(g_filter, g_filter)\n",
    "    return conv2(in1, g_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERTYPES = [\"gradient\", \"patch\", \"shape\"]\n",
    "\n",
    "\n",
    "class CKN(object):\n",
    "    \"\"\"docstring for CKN\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_sizes=[1, 2],\n",
    "        subsamplings=[2, 4],\n",
    "        map_dims={12, 200},\n",
    "        layer_type=\"gradient\",\n",
    "    ):\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.subsamplings = subsamplings\n",
    "        self.map_dims = map_dims\n",
    "        if layer_type in LAYERTYPES:\n",
    "            self.layer_type = layer_type\n",
    "        else:\n",
    "            raise ValueError(\"unknown layer type\")\n",
    "        self.n_layers = len(patch_sizes)\n",
    "\n",
    "    def train(self, images):\n",
    "        \"\"\"\n",
    "        images: n x sx x sx x channels\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        psis = images\n",
    "        n = images.shape[0]\n",
    "        for i in range(self.n_layers):\n",
    "            centering = (i == 0) and (self.layer_type == \"patch\")\n",
    "            layer = CKNLayer(\n",
    "                i,\n",
    "                centering,\n",
    "                self.layer_type,\n",
    "                self.patch_sizes[i],\n",
    "                self.map_dims[i],\n",
    "                self.subsamplings[i],\n",
    "            )\n",
    "\n",
    "            layer.train(psis)\n",
    "\n",
    "            self.layers.append(layer)\n",
    "            if i < self.n_layers - 1:\n",
    "                for j in range(n):\n",
    "                    psi = layer.forward(psis[j])\n",
    "                    if j == 0:\n",
    "                        out_psis = np.zeros((n,) + psi.shape)\n",
    "                    out_psis[j] = psi\n",
    "                psis = out_psis\n",
    "\n",
    "    def forward(self, image, layer=None):\n",
    "        \"\"\"output map of the i-th layer\n",
    "        layer: int < n_layers\n",
    "        image: sx x sx x channels\n",
    "        \"\"\"\n",
    "        if layer is None:\n",
    "            layer = self.n_layers\n",
    "        psi = image\n",
    "        for i in range(layer):\n",
    "            psi = self.layers[i].forward(psi)\n",
    "        return psi\n",
    "\n",
    "    def out_maps(self, images):\n",
    "        n = images.shape[0]\n",
    "        for i in range(n):\n",
    "            output_map = self.forward(images[i])\n",
    "            output_map = output_map.flatten()\n",
    "            if i == 0:\n",
    "                res = np.zeros((n, output_map.shape[0]))\n",
    "            res[i] = output_map\n",
    "        return res\n",
    "\n",
    "\n",
    "def save(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "class CKNLayer(object):\n",
    "    def __init__(self, order, centering, layer_type, patch_size, map_dim, subsampling):\n",
    "        self.order = order\n",
    "        self.centering = centering\n",
    "        self.layer_type = layer_type\n",
    "        self.patch_size = patch_size\n",
    "        self.map_dim = map_dim\n",
    "        self.subsampling = subsampling\n",
    "        self.n_patches_per_image = 10\n",
    "\n",
    "    def train(self, input_maps):\n",
    "        if self.order == 0 and self.layer_type == \"gradient\":\n",
    "            # no parameter training for gradient map\n",
    "            return\n",
    "        elif self.order == 0 and self.layer_type == \"shape\":\n",
    "            n = input_maps.shape[0]\n",
    "            for i in range(n):\n",
    "                psi = input_maps[i]\n",
    "                patch = extract_patches_2d(psi, self.patch_size)\n",
    "\n",
    "                patch = shape_patch(patch)\n",
    "                if i == 0:\n",
    "                    n_patches_per_image = np.minimum(\n",
    "                        2 * self.n_patches_per_image, patch.shape[0]\n",
    "                    )\n",
    "                    X = np.zeros((n * n_patches_per_image, patch.shape[1]))\n",
    "                # discard patches with no variance\n",
    "                idx = np.any(patch != patch[:, [0]], axis=1)\n",
    "                if n_patches_per_image <= idx.sum():\n",
    "                    patch = patch[idx]\n",
    "                np.random.shuffle(patch)\n",
    "                X[i * n_patches_per_image : (i + 1) * n_patches_per_image] = patch[\n",
    "                    :n_patches_per_image\n",
    "                ]\n",
    "            np.random.shuffle(X)\n",
    "            X = normalize_row(X, norm=\"l2\")\n",
    "            Z = spherical_kmeans(X, self.map_dim)[0]\n",
    "            self.Z = Z\n",
    "            self.sigma2 = 0.25\n",
    "            lin_tran = gaussian_func(Z.dot(Z.T), self.sigma2)\n",
    "            # svd decomposition to compute lin_tran^(-0.5)\n",
    "            w, v = np.linalg.eigh(lin_tran)\n",
    "            w = (w + 1e-8) ** (-0.5)\n",
    "            lin_tran = v.dot(np.diag(w).dot(v.T))\n",
    "            self.lin_tran = lin_tran\n",
    "        else:\n",
    "            n = input_maps.shape[0]\n",
    "            for i in range(n):\n",
    "                psi = input_maps[i]\n",
    "                patch = extract_patches_2d(psi, self.patch_size)\n",
    "                if self.centering:\n",
    "                    patch = centering_patch(patch)\n",
    "                # print patch.shape\n",
    "                patch = patch.reshape((patch.shape[0], -1))\n",
    "                if i == 0:\n",
    "                    n_patches_per_image = np.minimum(\n",
    "                        2 * self.n_patches_per_image, patch.shape[0]\n",
    "                    )\n",
    "                    X = np.zeros((n * n_patches_per_image, patch.shape[1]))\n",
    "                # discard patches with no variance\n",
    "                idx = np.any(patch != patch[:, [0]], axis=1)\n",
    "                if n_patches_per_image <= idx.sum():\n",
    "                    patch = patch[idx]\n",
    "                np.random.shuffle(patch)\n",
    "                X[i * n_patches_per_image : (i + 1) * n_patches_per_image] = patch[\n",
    "                    :n_patches_per_image\n",
    "                ]\n",
    "            np.random.shuffle(X)\n",
    "            X = normalize_row(X, norm=\"l2\")\n",
    "            Z = spherical_kmeans(X, self.map_dim)[0]\n",
    "            self.Z = Z\n",
    "            self.sigma2 = 0.25\n",
    "            lin_tran = gaussian_func(Z.dot(Z.T), self.sigma2)\n",
    "            # svd decomposition to compute lin_tran^(-0.5)\n",
    "            w, v = np.linalg.eigh(lin_tran)\n",
    "            w = (w + 1e-8) ** (-0.5)\n",
    "            lin_tran = v.dot(np.diag(w).dot(v.T))\n",
    "            self.lin_tran = lin_tran\n",
    "\n",
    "    def forward(self, input_map):\n",
    "        if self.order == 0 and self.layer_type == \"gradient\":\n",
    "            n_channels = input_map.shape[-1]\n",
    "            output_map = np.zeros(input_map.shape[:-1] + (self.map_dim * n_channels,))\n",
    "            theta = np.linspace(0, 2.0 * np.pi, self.map_dim + 1)[:-1]\n",
    "            delta_theta = 2.0 * np.pi / self.map_dim\n",
    "            sigma2 = np.square(1 - np.cos(delta_theta)) + np.square(np.sin(delta_theta))\n",
    "            self.sigma2 = sigma2\n",
    "            for k in range(n_channels):\n",
    "                input_map_k = input_map[:, :, k]\n",
    "                dx, dy = np.gradient(input_map_k)\n",
    "                rho = np.sqrt(np.square(dx) + np.square(dy))\n",
    "                idx = rho > 0\n",
    "                dx[idx] = dx[idx] / rho[idx]\n",
    "                dy[idx] = dy[idx] / rho[idx]\n",
    "                # sample theta between [0, 2*pi]\n",
    "                for i in range(self.map_dim):\n",
    "                    output_map[:, :, i + self.map_dim * k] = rho * gaussian_func(\n",
    "                        dx * np.cos(theta[i]) + dy * np.sin(theta[i]), sigma2\n",
    "                    )\n",
    "        elif self.order == 0 and self.layer_type == \"shape\":\n",
    "            # we suppose that patch_size is odd\n",
    "            n_channels = input_map.shape[-1]\n",
    "            patch = extract_patches_2d(input_map, self.patch_size)\n",
    "            size = input_map.shape[0] - self.patch_size + 1\n",
    "            patch = shape_patch(patch)\n",
    "            patch, rho = normalize_row(patch, norm=\"l2\", return_norm=True)\n",
    "\n",
    "            output_map = gaussian_func(patch.dot(self.Z.T), self.sigma2)\n",
    "            output_map = np.diag(rho).dot(output_map.dot(self.lin_tran))\n",
    "            output_map = output_map.reshape((size, size, -1))\n",
    "        else:\n",
    "            patch = extract_patches_2d(input_map, self.patch_size)\n",
    "            size = input_map.shape[0] - self.patch_size + 1\n",
    "            # centering\n",
    "            if self.centering:\n",
    "                patch = centering_patch(patch)\n",
    "\n",
    "            patch = patch.reshape((patch.shape[0], -1))\n",
    "\n",
    "            patch, rho = normalize_row(patch, norm=\"l2\", return_norm=True)\n",
    "            output_map = gaussian_func(patch.dot(self.Z.T), self.sigma2)\n",
    "            output_map = np.diag(rho).dot(output_map.dot(self.lin_tran))\n",
    "            output_map = output_map.reshape((size, size, -1))\n",
    "\n",
    "        # gaussian smoothing\n",
    "        for i in range(output_map.shape[-1]):\n",
    "            output_map[:, :, i] = conv2_gaussian(\n",
    "                output_map[:, :, i],\n",
    "                2 * self.subsampling + 1,\n",
    "                self.subsampling / np.sqrt(2),\n",
    "            )\n",
    "        output_map = output_map[\n",
    "            int((self.subsampling - 1) // 2) :: self.subsampling,\n",
    "            int((self.subsampling - 1) // 2) :: self.subsampling,\n",
    "            :,\n",
    "        ]\n",
    "        return output_map\n",
    "\n",
    "\n",
    "def gaussian_func(x, sigma2):\n",
    "    return np.exp(1 / sigma2 * (x - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "data_path = os.path.join(current_path ,\"data\")\n",
    "# data_folder = \n",
    "X, y, X_test = utils.load_data(data_folder=data_path)\n",
    "X, y, X_eval, y_eval \n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spherical kmeans iter 10, objective: 0.736805\n",
      "spherical kmeans iter 20, objective: 0.736147\n",
      "spherical kmeans iter 30, objective: 0.736058\n",
      "spherical kmeans iter 40, objective: 0.735939\n",
      "spherical kmeans iter 50, objective: 0.735849\n",
      "spherical kmeans iter 60, objective: 0.735817\n",
      "spherical kmeans iter 70, objective: 0.735804\n",
      "spherical kmeans iter 80, objective: 0.735813\n",
      "spherical kmeans iter 90, objective: 0.735761\n",
      "spherical kmeans iter 100, objective: 0.735751\n",
      "spherical kmeans iter 110, objective: 0.735755\n",
      "spherical kmeans iter 120, objective: 0.735751\n",
      "spherical kmeans iter 130, objective: 0.735738\n",
      "spherical kmeans iter 140, objective: 0.735740\n",
      "spherical kmeans iter 150, objective: 0.735740\n",
      "spherical kmeans iter 160, objective: 0.735745\n",
      "spherical kmeans iter 170, objective: 0.735737\n",
      "spherical kmeans iter 180, objective: 0.735733\n",
      "spherical kmeans iter 190, objective: 0.735737\n",
      "ckn training time: 55.30 s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "train = True\n",
    "save_model = False\n",
    "prediction = False\n",
    "save_svm_model = False\n",
    "\n",
    "\n",
    "model1 = CKN([1, 2], [2, 4], [12, 200], \"gradient\")\n",
    "model2 = CKN([2, 2], [2, 4], [100, 200], \"patch\")\n",
    "model3 = CKN([3], [10], [200], \"patch\")\n",
    "# model4 = CKN([3, 2], [2, 4], [100, 200], 'shape')\n",
    "models = [model1, model2, model3]\n",
    "\n",
    "norms = []\n",
    "X_ckn_tr = []\n",
    "for i, model in enumerate(models):\n",
    "    if train:\n",
    "        tic = time.time()\n",
    "        model.train(X)\n",
    "        toc = time.time()\n",
    "        print((\"ckn training time: %.2f s\" % (toc - tic)))\n",
    "        if save_model:\n",
    "            save(model, \"model/\" + model.layer_type + \"_\" + str(model.n_layers))\n",
    "    else:\n",
    "        model = load(\"model/\" + model.layer_type + \"_\" + str(model.n_layers))\n",
    "        models[i] = model\n",
    "    X_ckn = model.out_maps(X)\n",
    "    X_ckn = X_ckn - X_ckn.mean(axis=1, keepdims=1)\n",
    "    norm = np.mean(np.sqrt(np.sum(np.square(X_ckn), axis=1)))\n",
    "    X_ckn = X_ckn / norm\n",
    "    norms.append(norm)\n",
    "    X_ckn_tr.append(X_ckn)\n",
    "\n",
    "X_ckn_tr = np.hstack(X_ckn_tr)\n",
    "del X\n",
    "del X_ckn\n",
    "\n",
    "print(X_ckn_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
