{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import numbers\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from utils_fast import conv2\n",
    "import pickle\n",
    "from kernelchallenge.load_data import load_data\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred(y_pred, outpath=\"output/\"):\n",
    "    ids = np.arange(1, 2001, dtype=int)\n",
    "    arr = np.hstack((ids.reshape(-1, 1), y_pred.reshape(-1, 1)))\n",
    "    arr = arr.astype(int)\n",
    "    np.savetxt(\n",
    "        outpath + \"Yte.csv\",\n",
    "        arr,\n",
    "        header=\"Id,Prediction\",\n",
    "        fmt=\"%d,%d\",\n",
    "        delimiter=\",\",\n",
    "        comments=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def reshape(images, sx=32, n_channels=3):\n",
    "    return images.reshape((-1, n_channels, sx, sx)).swapaxes(1, 2).swapaxes(2, 3)\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"visualize image of given vec: 1 x 3072\"\"\"\n",
    "    if img.ndim < 3:\n",
    "        print(\"ok\")\n",
    "        img = img.reshape((32, 32, 3), order=\"F\")\n",
    "        img = img.swapaxes(0, 1)\n",
    "    for i in range(3):\n",
    "        minval = img[:, :, i].min()\n",
    "        maxval = img[:, :, i].max()\n",
    "        if minval != maxval:\n",
    "            img[:, :, i] -= minval\n",
    "            img[:, :, i] *= 1.0 / (maxval - minval)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def distribution_y(filepath=\"data/\"):\n",
    "    y = np.genfromtxt(filepath + \"Ytr.csv\", delimiter=\",\", skip_header=1, dtype=int)[\n",
    "        :, -1\n",
    "    ]\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(y)\n",
    "    vmin = y.min()\n",
    "    vmax = y.max()\n",
    "    plt.hist(y, bins=np.arange(vmin - 0.5, vmax + 1.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_random_state(seed):\n",
    "    \"\"\"Turn seed into a np.random.RandomState instance\n",
    "    If seed is None, return the RandomState singleton used by np.random.\n",
    "    If seed is an int, return a new RandomState instance seeded with seed.\n",
    "    If seed is already a RandomState instance, return it.\n",
    "    Otherwise raise ValueError.\n",
    "    \"\"\"\n",
    "    if seed is None or seed is np.random:\n",
    "        return np.random.mtrand._rand\n",
    "    if isinstance(seed, (numbers.Integral, np.integer)):\n",
    "        return np.random.RandomState(seed)\n",
    "    if isinstance(seed, np.random.RandomState):\n",
    "        return seed\n",
    "    raise ValueError(\n",
    "        \"%r cannot be used to seed a numpy.random.RandomState\" \" instance\" % seed\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_patches_2d(image, patch_size, step=1):\n",
    "    \"\"\"image : nx x ny x n_channels\n",
    "    output: n_patches x patch_size x patch_size x n_channels\n",
    "    \"\"\"\n",
    "    n_channels = image.shape[-1]\n",
    "    patches = extract_patches(image, (patch_size, patch_size, n_channels), step)\n",
    "    return patches.reshape(-1, patch_size, patch_size, n_channels)\n",
    "\n",
    "\n",
    "def extract_patches(arr, patch_shape, extraction_step):\n",
    "    if isinstance(extraction_step, int):\n",
    "        extraction_step = tuple([extraction_step] * arr.ndim)\n",
    "    patch_strides = arr.strides\n",
    "    slices = tuple(slice(None, None, st) for st in extraction_step)\n",
    "    # print(slices, type(arr), arr)\n",
    "    # slices\n",
    "    indexing_strides = arr[slices].strides\n",
    "\n",
    "    patch_indices_shape = (\n",
    "        (np.array(arr.shape) - np.array(patch_shape)) // np.array(extraction_step)\n",
    "    ) + 1\n",
    "\n",
    "    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n",
    "    strides = tuple(list(indexing_strides) + list(patch_strides))\n",
    "\n",
    "    patches = as_strided(arr, shape=shape, strides=strides)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def centering_patch(patch):\n",
    "    return patch - np.mean(patch, axis=(1, 2), keepdims=1)\n",
    "\n",
    "\n",
    "def shape_patch(patch, threshold=1e-6):\n",
    "    \"\"\"patch: n_patches x size x size x n_channels\n",
    "    output: n_patches x (size^2-1)n_channels\n",
    "    \"\"\"\n",
    "    n_channels = patch.shape[-1]\n",
    "    patch = patch.reshape((patch.shape[0], -1, patch.shape[-1]))\n",
    "    center = int(patch.shape[1] // 2)\n",
    "    patch = patch - patch[:, [center], :]\n",
    "    patch = np.delete(patch, center, 1)  # remove center\n",
    "    patch = patch.reshape((patch.shape[0], -1))\n",
    "    # rho = np.linalg.norm(patch, axis=1)\n",
    "    # rho[rho<threshold] = 0\n",
    "    # # binarize the difference\n",
    "    # cond = patch > 0\n",
    "    # non_cond = patch <= 0\n",
    "    # patch[cond] = 1.0\n",
    "    # patch[non_cond] = 0.0\n",
    "    return patch\n",
    "\n",
    "\n",
    "def normalize_row(X, norm=\"l2\", threshold=1e-5, return_norm=False):\n",
    "    if norm == \"l2\":\n",
    "        norms = np.linalg.norm(X, axis=1)\n",
    "        norms[norms < threshold] = threshold\n",
    "        X /= norms[:, np.newaxis]\n",
    "    if return_norm:\n",
    "        return X, norms\n",
    "    return X\n",
    "\n",
    "\n",
    "def kmeans(X, k, max_iter=1000, init=None):\n",
    "    \"\"\"normal kmeans\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    if init is None:\n",
    "        perm = np.random.choice(np.arange(n_samples), k)\n",
    "        centroids = X[perm]\n",
    "\n",
    "    norm2 = np.linalg.norm(X, axis=1, keepdims=1) ** 2\n",
    "    prev_obj = np.inf\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        dist2 = (\n",
    "            np.linalg.norm(centroids, axis=1) ** 2\n",
    "            - 2.0 * np.dot(X, centroids.T)\n",
    "            + norm2\n",
    "        )\n",
    "        assign = np.argmin(dist2, axis=1)\n",
    "        obj = dist2[np.unravel_index(assign, dist2.shape)].mean()\n",
    "        # print dist.shape\n",
    "        if (n_iter + 1) % 10 == 0:\n",
    "            print((\"kmeans iter %d, objective: %f\" % (n_iter + 1, obj)))\n",
    "\n",
    "        for j in range(k):\n",
    "            Xj = X[assign == j]\n",
    "            if Xj.shape[0] == 0:\n",
    "                centroids[j] = X[np.random.randint(n_samples)]\n",
    "            else:\n",
    "                centroids[j] = np.mean(Xj, axis=0)\n",
    "\n",
    "        if np.abs(prev_obj - obj) / (np.abs(obj) + 1e-20) < 1e-8:\n",
    "            break\n",
    "        prev_obj = obj\n",
    "\n",
    "        # stop criteria\n",
    "    return centroids, assign\n",
    "\n",
    "\n",
    "def spherical_kmeans(X, k, max_iter=1000, init=None):\n",
    "    \"\"\"X: n x d points with unit-norm\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    if init is None:\n",
    "        perm = np.random.choice(np.arange(n_samples), k)\n",
    "        centroids = X[perm]\n",
    "\n",
    "    prev_obj = np.inf\n",
    "    for n_iter in range(max_iter):\n",
    "        cos_sim = np.dot(X, centroids.T)\n",
    "        assign = np.argmax(cos_sim, axis=1)\n",
    "        obj = cos_sim[np.unravel_index(assign, cos_sim.shape)].mean()\n",
    "\n",
    "        if (n_iter + 1) % 10 == 0:\n",
    "            print((\"spherical kmeans iter %d, objective: %f\" % (n_iter + 1, obj)))\n",
    "\n",
    "        for j in range(k):\n",
    "            Xj = X[assign == j]\n",
    "            if Xj.shape[0] == 0:\n",
    "                centroids[j] = X[np.random.randint(n_samples)]\n",
    "            else:\n",
    "                centroids[j] = np.sum(Xj, axis=0)\n",
    "                norm = np.linalg.norm(centroids[j])\n",
    "                centroids[j] /= norm\n",
    "        if np.abs(prev_obj - obj) / (np.abs(obj) + 1e-20) < 1e-8:\n",
    "            break\n",
    "        prev_obj = obj\n",
    "\n",
    "    return centroids, assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_1d(shape, sigma):\n",
    "    m = (shape - 1.0) / 2.0\n",
    "    filt = np.arange(-m, m + 1)\n",
    "    filt = np.exp(-np.square(filt) / (2.0 * sigma**2))\n",
    "    return filt / np.sum(filt)\n",
    "\n",
    "\n",
    "def conv2_gaussian(in1, shape, sigma=0.5):\n",
    "    g_filter = gaussian_filter_1d(shape, sigma)\n",
    "    g_filter = np.outer(g_filter, g_filter)\n",
    "    return conv2(in1, g_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERTYPES = [\"gradient\", \"patch\", \"shape\"]\n",
    "\n",
    "\n",
    "class CKN(object):\n",
    "    \"\"\"docstring for CKN\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_sizes=[1, 2],\n",
    "        subsamplings=[2, 4],\n",
    "        map_dims={12, 200},\n",
    "        layer_type=\"gradient\",\n",
    "    ):\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.subsamplings = subsamplings\n",
    "        self.map_dims = map_dims\n",
    "        if layer_type in LAYERTYPES:\n",
    "            self.layer_type = layer_type\n",
    "        else:\n",
    "            raise ValueError(\"unknown layer type\")\n",
    "        self.n_layers = len(patch_sizes)\n",
    "\n",
    "    def train(self, images):\n",
    "        \"\"\"\n",
    "        images: n x sx x sx x channels\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        psis = images\n",
    "        n = images.shape[0]\n",
    "        for i in range(self.n_layers):\n",
    "            centering = (i == 0) and (self.layer_type == \"patch\")\n",
    "            layer = CKNLayer(\n",
    "                i,\n",
    "                centering,\n",
    "                self.layer_type,\n",
    "                self.patch_sizes[i],\n",
    "                self.map_dims[i],\n",
    "                self.subsamplings[i],\n",
    "            )\n",
    "\n",
    "            layer.train(psis)\n",
    "\n",
    "            self.layers.append(layer)\n",
    "            if i < self.n_layers - 1:\n",
    "                for j in range(n):\n",
    "                    psi = layer.forward(psis[j])\n",
    "                    if j == 0:\n",
    "                        out_psis = np.zeros((n,) + psi.shape)\n",
    "                    out_psis[j] = psi\n",
    "                psis = out_psis\n",
    "\n",
    "    def forward(self, image, layer=None):\n",
    "        \"\"\"output map of the i-th layer\n",
    "        layer: int < n_layers\n",
    "        image: sx x sx x channels\n",
    "        \"\"\"\n",
    "        if layer is None:\n",
    "            layer = self.n_layers\n",
    "        psi = image\n",
    "        for i in range(layer):\n",
    "            psi = self.layers[i].forward(psi)\n",
    "        return psi\n",
    "\n",
    "    def out_maps(self, images):\n",
    "        n = images.shape[0]\n",
    "        for i in range(n):\n",
    "            output_map = self.forward(images[i])\n",
    "            output_map = output_map.flatten()\n",
    "            if i == 0:\n",
    "                res = np.zeros((n, output_map.shape[0]))\n",
    "            res[i] = output_map\n",
    "        return res\n",
    "\n",
    "\n",
    "def save(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "class CKNLayer(object):\n",
    "    def __init__(self, order, centering, layer_type, patch_size, map_dim, subsampling):\n",
    "        self.order = order\n",
    "        self.centering = centering\n",
    "        self.layer_type = layer_type\n",
    "        self.patch_size = patch_size\n",
    "        self.map_dim = map_dim\n",
    "        self.subsampling = subsampling\n",
    "        self.n_patches_per_image = 10\n",
    "\n",
    "    def train(self, input_maps):\n",
    "        if self.order == 0 and self.layer_type == \"gradient\":\n",
    "            # no parameter training for gradient map\n",
    "            return\n",
    "        elif self.order == 0 and self.layer_type == \"shape\":\n",
    "            n = input_maps.shape[0]\n",
    "            for i in range(n):\n",
    "                psi = input_maps[i]\n",
    "                patch = extract_patches_2d(psi, self.patch_size)\n",
    "\n",
    "                patch = shape_patch(patch)\n",
    "                if i == 0:\n",
    "                    n_patches_per_image = np.minimum(\n",
    "                        2 * self.n_patches_per_image, patch.shape[0]\n",
    "                    )\n",
    "                    X = np.zeros((n * n_patches_per_image, patch.shape[1]))\n",
    "                # discard patches with no variance\n",
    "                idx = np.any(patch != patch[:, [0]], axis=1)\n",
    "                if n_patches_per_image <= idx.sum():\n",
    "                    patch = patch[idx]\n",
    "                np.random.shuffle(patch)\n",
    "                X[i * n_patches_per_image : (i + 1) * n_patches_per_image] = patch[\n",
    "                    :n_patches_per_image\n",
    "                ]\n",
    "            np.random.shuffle(X)\n",
    "            X = normalize_row(X, norm=\"l2\")\n",
    "            Z = spherical_kmeans(X, self.map_dim)[0]\n",
    "            self.Z = Z\n",
    "            self.sigma2 = 0.25\n",
    "            lin_tran = gaussian_func(Z.dot(Z.T), self.sigma2)\n",
    "            # svd decomposition to compute lin_tran^(-0.5)\n",
    "            w, v = np.linalg.eigh(lin_tran)\n",
    "            w = (w + 1e-8) ** (-0.5)\n",
    "            lin_tran = v.dot(np.diag(w).dot(v.T))\n",
    "            self.lin_tran = lin_tran\n",
    "        else:\n",
    "            n = input_maps.shape[0]\n",
    "            for i in range(n):\n",
    "                psi = input_maps[i]\n",
    "                patch = extract_patches_2d(psi, self.patch_size)\n",
    "                if self.centering:\n",
    "                    patch = centering_patch(patch)\n",
    "                # print patch.shape\n",
    "                patch = patch.reshape((patch.shape[0], -1))\n",
    "                if i == 0:\n",
    "                    n_patches_per_image = np.minimum(\n",
    "                        2 * self.n_patches_per_image, patch.shape[0]\n",
    "                    )\n",
    "                    X = np.zeros((n * n_patches_per_image, patch.shape[1]))\n",
    "                # discard patches with no variance\n",
    "                idx = np.any(patch != patch[:, [0]], axis=1)\n",
    "                if n_patches_per_image <= idx.sum():\n",
    "                    patch = patch[idx]\n",
    "                np.random.shuffle(patch)\n",
    "                X[i * n_patches_per_image : (i + 1) * n_patches_per_image] = patch[\n",
    "                    :n_patches_per_image\n",
    "                ]\n",
    "            np.random.shuffle(X)\n",
    "            X = normalize_row(X, norm=\"l2\")\n",
    "            Z = spherical_kmeans(X, self.map_dim)[0]\n",
    "            self.Z = Z\n",
    "            self.sigma2 = 0.25\n",
    "            lin_tran = gaussian_func(Z.dot(Z.T), self.sigma2)\n",
    "            # svd decomposition to compute lin_tran^(-0.5)\n",
    "            w, v = np.linalg.eigh(lin_tran)\n",
    "            w = (w + 1e-8) ** (-0.5)\n",
    "            lin_tran = v.dot(np.diag(w).dot(v.T))\n",
    "            self.lin_tran = lin_tran\n",
    "\n",
    "    def forward(self, input_map):\n",
    "        if self.order == 0 and self.layer_type == \"gradient\":\n",
    "            n_channels = input_map.shape[-1]\n",
    "            output_map = np.zeros(input_map.shape[:-1] + (self.map_dim * n_channels,))\n",
    "            theta = np.linspace(0, 2.0 * np.pi, self.map_dim + 1)[:-1]\n",
    "            delta_theta = 2.0 * np.pi / self.map_dim\n",
    "            sigma2 = np.square(1 - np.cos(delta_theta)) + np.square(np.sin(delta_theta))\n",
    "            self.sigma2 = sigma2\n",
    "            for k in range(n_channels):\n",
    "                input_map_k = input_map[:, :, k]\n",
    "                dx, dy = np.gradient(input_map_k)\n",
    "                rho = np.sqrt(np.square(dx) + np.square(dy))\n",
    "                idx = rho > 0\n",
    "                dx[idx] = dx[idx] / rho[idx]\n",
    "                dy[idx] = dy[idx] / rho[idx]\n",
    "                # sample theta between [0, 2*pi]\n",
    "                for i in range(self.map_dim):\n",
    "                    output_map[:, :, i + self.map_dim * k] = rho * gaussian_func(\n",
    "                        dx * np.cos(theta[i]) + dy * np.sin(theta[i]), sigma2\n",
    "                    )\n",
    "        elif self.order == 0 and self.layer_type == \"shape\":\n",
    "            # we suppose that patch_size is odd\n",
    "            n_channels = input_map.shape[-1]\n",
    "            patch = extract_patches_2d(input_map, self.patch_size)\n",
    "            size = input_map.shape[0] - self.patch_size + 1\n",
    "            patch = shape_patch(patch)\n",
    "            patch, rho = normalize_row(patch, norm=\"l2\", return_norm=True)\n",
    "\n",
    "            output_map = gaussian_func(patch.dot(self.Z.T), self.sigma2)\n",
    "            output_map = np.diag(rho).dot(output_map.dot(self.lin_tran))\n",
    "            output_map = output_map.reshape((size, size, -1))\n",
    "        else:\n",
    "            patch = extract_patches_2d(input_map, self.patch_size)\n",
    "            size = input_map.shape[0] - self.patch_size + 1\n",
    "            # centering\n",
    "            if self.centering:\n",
    "                patch = centering_patch(patch)\n",
    "\n",
    "            patch = patch.reshape((patch.shape[0], -1))\n",
    "\n",
    "            patch, rho = normalize_row(patch, norm=\"l2\", return_norm=True)\n",
    "            output_map = gaussian_func(patch.dot(self.Z.T), self.sigma2)\n",
    "            output_map = np.diag(rho).dot(output_map.dot(self.lin_tran))\n",
    "            output_map = output_map.reshape((size, size, -1))\n",
    "\n",
    "        # gaussian smoothing\n",
    "        for i in range(output_map.shape[-1]):\n",
    "            output_map[:, :, i] = conv2_gaussian(\n",
    "                output_map[:, :, i],\n",
    "                2 * self.subsampling + 1,\n",
    "                self.subsampling / np.sqrt(2),\n",
    "            )\n",
    "        output_map = output_map[\n",
    "            int((self.subsampling - 1) // 2) :: self.subsampling,\n",
    "            int((self.subsampling - 1) // 2) :: self.subsampling,\n",
    "            :,\n",
    "        ]\n",
    "        \n",
    "        return output_map\n",
    "\n",
    "\n",
    "def gaussian_func(x, sigma2):\n",
    "    return np.exp(1 / sigma2 * (x - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "data_path = os.path.join(current_path, \"data\")\n",
    "# data_folder =\n",
    "X, y, X_test = load_data(data_folder=data_path)\n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spherical kmeans iter 10, objective: 0.736805\n",
      "spherical kmeans iter 20, objective: 0.736147\n",
      "spherical kmeans iter 30, objective: 0.736058\n",
      "spherical kmeans iter 40, objective: 0.735939\n",
      "spherical kmeans iter 50, objective: 0.735849\n",
      "spherical kmeans iter 60, objective: 0.735817\n",
      "spherical kmeans iter 70, objective: 0.735804\n",
      "spherical kmeans iter 80, objective: 0.735813\n",
      "spherical kmeans iter 90, objective: 0.735761\n",
      "spherical kmeans iter 100, objective: 0.735751\n",
      "spherical kmeans iter 110, objective: 0.735755\n",
      "spherical kmeans iter 120, objective: 0.735751\n",
      "spherical kmeans iter 130, objective: 0.735738\n",
      "spherical kmeans iter 140, objective: 0.735740\n",
      "spherical kmeans iter 150, objective: 0.735740\n",
      "spherical kmeans iter 160, objective: 0.735745\n",
      "spherical kmeans iter 170, objective: 0.735737\n",
      "spherical kmeans iter 180, objective: 0.735733\n",
      "spherical kmeans iter 190, objective: 0.735737\n",
      "ckn training time: 102.08 s\n",
      "(5000, 3200)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "train = True\n",
    "save_model = False\n",
    "prediction = False\n",
    "save_svm_model = False\n",
    "\n",
    "\n",
    "model1 = CKN([1, 2], [2, 4], [12, 200], \"gradient\")\n",
    "# model2 = CKN([1, 2], [2, 4], [12, 200], \"patch\")\n",
    "\n",
    "# model2 = CKN([2, 2], [2, 4], [100, 200], \"patch\")\n",
    "# model3 = CKN([3], [10], [200], \"patch\")\n",
    "# model4 = CKN([3, 2], [2, 4], [100, 200], 'shape')\n",
    "models = [model1]\n",
    "\n",
    "norms = []\n",
    "X_ckn_tr = []\n",
    "for i, model in enumerate(models):\n",
    "    if train:\n",
    "        tic = time.time()\n",
    "        model.train(X)\n",
    "        toc = time.time()\n",
    "        print((\"ckn training time: %.2f s\" % (toc - tic)))\n",
    "        if save_model:\n",
    "            save(model, \"model/\" + model.layer_type + \"_\" + str(model.n_layers))\n",
    "    else:\n",
    "        model = load(\"model/\" + model.layer_type + \"_\" + str(model.n_layers))\n",
    "        models[i] = model\n",
    "        \n",
    "        \n",
    "    X_ckn = model.out_maps(X)\n",
    "    X_ckn = X_ckn - X_ckn.mean(axis=1, keepdims=1)\n",
    "    norm = np.mean(np.sqrt(np.sum(np.square(X_ckn), axis=1)))\n",
    "    X_ckn = X_ckn / norm\n",
    "    norms.append(norm)\n",
    "    X_ckn_tr.append(X_ckn)\n",
    "\n",
    "X_ckn_tr = np.hstack(X_ckn_tr)\n",
    "del X\n",
    "del X_ckn\n",
    "\n",
    "print(X_ckn_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]*\n",
      "optimization finished, #iter = 744\n",
      "obj = -187.234401, rho = 0.274540\n",
      "nSV = 491, nBSV = 177\n",
      "*\n",
      "optimization finished, #iter = 699\n",
      "obj = -236.683357, rho = -0.201482\n",
      "nSV = 495, nBSV = 234\n",
      "*\n",
      "optimization finished, #iter = 647\n",
      "obj = -188.136555, rho = -0.204633\n",
      "nSV = 428, nBSV = 171\n",
      "*\n",
      "optimization finished, #iter = 599\n",
      "obj = -188.693199, rho = -0.566590\n",
      "nSV = 416, nBSV = 181\n",
      "*\n",
      "optimization finished, #iter = 592\n",
      "obj = -146.974821, rho = -0.183609\n",
      "nSV = 362, nBSV = 129\n",
      "*\n",
      "optimization finished, #iter = 598\n",
      "obj = -135.544096, rho = -0.200461\n",
      "nSV = 368, nBSV = 104\n",
      "*\n",
      "optimization finished, #iter = 646\n",
      "obj = -161.012595, rho = -0.182686\n",
      "nSV = 407, nBSV = 136\n",
      "*.*\n",
      "optimization finished, #iter = 819\n",
      "obj = -303.260125, rho = -0.316938\n",
      "nSV = 603, nBSV = 326\n",
      "*\n",
      "optimization finished, #iter = 692\n",
      "obj = -177.148999, rho = 0.121934\n",
      "nSV = 449, nBSV = 167\n",
      "*\n",
      "optimization finished, #iter = 658\n",
      "obj = -140.630517, rho = -0.497333\n",
      "nSV = 406, nBSV = 110\n",
      "*\n",
      "optimization finished, #iter = 640\n",
      "obj = -138.062382, rho = -0.624769\n",
      "nSV = 406, nBSV = 117\n",
      "*\n",
      "optimization finished, #iter = 621\n",
      "obj = -117.258108, rho = -0.698868\n",
      "nSV = 353, nBSV = 84\n",
      "*\n",
      "optimization finished, #iter = 571\n",
      "obj = -113.574988, rho = -0.570288\n",
      "nSV = 348, nBSV = 88\n",
      "*\n",
      "optimization finished, #iter = 655\n",
      "obj = -153.155967, rho = -0.454654\n",
      "nSV = 419, nBSV = 126\n",
      "*\n",
      "optimization finished, #iter = 625\n",
      "obj = -129.444913, rho = -0.523885\n",
      "nSV = 393, nBSV = 97\n",
      "*\n",
      "optimization finished, #iter = 783\n",
      "obj = -212.446416, rho = -0.575896\n",
      "nSV = 521, nBSV = 207\n",
      "*\n",
      "optimization finished, #iter = 797\n",
      "obj = -225.815444, rho = -0.201348\n",
      "nSV = 553, nBSV = 210\n",
      "*.*\n",
      "optimization finished, #iter = 857\n",
      "obj = -355.686490, rho = -0.048591\n",
      "nSV = 669, nBSV = 382\n",
      "*\n",
      "optimization finished, #iter = 762\n",
      "obj = -311.181169, rho = -0.459296\n",
      "nSV = 580, nBSV = 330\n",
      "*.*\n",
      "optimization finished, #iter = 805\n",
      "obj = -330.177489, rho = -0.146626\n",
      "nSV = 619, nBSV = 349\n",
      "*\n",
      "optimization finished, #iter = 717\n",
      "obj = -242.821969, rho = -0.038020\n",
      "nSV = 495, nBSV = 233\n",
      "*.*\n",
      "optimization finished, #iter = 840\n",
      "obj = -273.910398, rho = -0.064838\n",
      "nSV = 590, nBSV = 277\n",
      "*\n",
      "optimization finished, #iter = 630\n",
      "obj = -173.287701, rho = -0.017287\n",
      "nSV = 420, nBSV = 174\n",
      "*\n",
      "optimization finished, #iter = 741\n",
      "obj = -170.232204, rho = 0.350721\n",
      "nSV = 467, nBSV = 154\n",
      "*\n",
      "optimization finished, #iter = 804\n",
      "obj = -319.467540, rho = -0.510825\n",
      "nSV = 607, nBSV = 344\n",
      "*\n",
      "optimization finished, #iter = 775\n",
      "obj = -389.339716, rho = 0.019938\n",
      "nSV = 669, nBSV = 423\n",
      "*\n",
      "optimization finished, #iter = 750\n",
      "obj = -262.893651, rho = 0.094895\n",
      "nSV = 533, nBSV = 249\n",
      "*.*\n",
      "optimization finished, #iter = 819\n",
      "obj = -275.135300, rho = 0.210109\n",
      "nSV = 578, nBSV = 275\n",
      "*\n",
      "optimization finished, #iter = 573\n",
      "obj = -165.804010, rho = 0.020941\n",
      "nSV = 387, nBSV = 156\n",
      "*\n",
      "optimization finished, #iter = 790\n",
      "obj = -200.844070, rho = 0.455744\n",
      "nSV = 504, nBSV = 187\n",
      "*\n",
      "optimization finished, #iter = 731\n",
      "obj = -267.357997, rho = 0.526446\n",
      "nSV = 525, nBSV = 269\n",
      "*\n",
      "optimization finished, #iter = 719\n",
      "obj = -234.586053, rho = 0.472355\n",
      "nSV = 493, nBSV = 235\n",
      "*\n",
      "optimization finished, #iter = 701\n",
      "obj = -273.280856, rho = 0.600222\n",
      "nSV = 535, nBSV = 292\n",
      "*\n",
      "optimization finished, #iter = 540\n",
      "obj = -147.962606, rho = 0.275147\n",
      "nSV = 353, nBSV = 133\n",
      "*\n",
      "optimization finished, #iter = 691\n",
      "obj = -166.984173, rho = 0.638391\n",
      "nSV = 444, nBSV = 155\n",
      "*\n",
      "optimization finished, #iter = 676\n",
      "obj = -225.620692, rho = 0.100077\n",
      "nSV = 465, nBSV = 216\n",
      "*\n",
      "optimization finished, #iter = 750\n",
      "obj = -286.336454, rho = 0.165403\n",
      "nSV = 575, nBSV = 304\n",
      "*\n",
      "optimization finished, #iter = 494\n",
      "obj = -118.213933, rho = -0.004067\n",
      "nSV = 318, nBSV = 102\n",
      "*\n",
      "optimization finished, #iter = 739\n",
      "obj = -169.899607, rho = 0.398953\n",
      "nSV = 465, nBSV = 146\n",
      "*\n",
      "optimization finished, #iter = 710\n",
      "obj = -187.658021, rho = 0.027118\n",
      "nSV = 453, nBSV = 167\n",
      "*\n",
      "optimization finished, #iter = 574\n",
      "obj = -128.386260, rho = 0.021449\n",
      "nSV = 348, nBSV = 110\n",
      "*\n",
      "optimization finished, #iter = 777\n",
      "obj = -176.393195, rho = 0.284887\n",
      "nSV = 481, nBSV = 154\n",
      "*\n",
      "optimization finished, #iter = 540\n",
      "obj = -126.607271, rho = 0.018754\n",
      "nSV = 347, nBSV = 108\n",
      "*\n",
      "optimization finished, #iter = 776\n",
      "obj = -197.466880, rho = 0.259887\n",
      "nSV = 496, nBSV = 178\n",
      "*\n",
      "optimization finished, #iter = 696\n",
      "obj = -196.591401, rho = 0.364850\n",
      "nSV = 468, nBSV = 183\n",
      "Total nSV = 3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 9 5 8 6 6 9 4 6 2 2 8 3 0 7 6 1 2 7 4 1 3 5 1 6 1 0 5 7 8 2 0 6 3 6 8 5\n",
      " 5 5 0 1 4 4 6 9 0 2 3 0 3 8 9 1 3 6 1 7 2 0 8 5 4 8 0 2 4 3 0 1 3 7 2 4 8\n",
      " 2 5 3 5 5 6 1 9 2 9 1 6 8 8 3 2 2 6 7 8 8 4 8 0 1 9 8 4 8 9 3 6 8 1 7 5 5\n",
      " 1 9 2 4 7 5 4 9 3 9 5 6 1 5 6 7 7 3 4 6 8 6 6 1 3 4 9 2 5 2 3 0 7 1 9 5 1\n",
      " 1 7 1 3 2 2 7 9 4 9 6 9 3 9 7 0 6 1 9 9 4 4 9 8 9 7 4 6 1 5 0 0 2 4 6 9 5\n",
      " 4 3 6 4 2 4 3 9 1 6 9 1 8 3 5 9 7 4 9 0 4 6 6 5 1 7 3 3 0 9 4 8 6 3 8 0 0\n",
      " 9 2 6 5 6 0 1 3 0 3 3 0 9 9 7 8 2 5 1 2 9 2 2 8 3 9 0 0 3 8 0 1 0 5 4 9 0\n",
      " 4 3 9 6 3 8 1 3 1 5 1 9 3 2 7 6 3 6 8 6 8 6 0 9 0 0 0 0 7 9 5 2 2 3 9 8 1\n",
      " 5 6 1 9 4 9 9 4 1 9 5 8 6 6 1 0 2 0 0 3 6 7 4 0 5 9 6 2 1 6 2 1 4 1 8 2 6\n",
      " 6 6 8 7 1 7 3 5 1 0 6 9 9 2 7 1 1 6 2 2 5 0 3 4 5 2 3 5 5 6 3 1 7 0 6 2 9\n",
      " 9 7 1 7 3 4 4 3 1 0 4 3 8 8 5 0 8 6 6 1 4 7 2 9 3 9 9 4 5 1 1 4 5 8 0 1 1\n",
      " 7 4 3 9 2 5 4 0 6 1 4 8 3 4 6 8 0 2 7 2 8 3 1 4 2 8 2 7 6 5 4 6 2 3 4 0 6\n",
      " 4 5 6 7 8 2 0 1 5 0 4 1 1 3 9 7 7 9 0 5 6 2 8 6 3 3 8 1 9 3 9 3 6 8 2 9 9\n",
      " 3 2 2 4 6 4 3 8 0 9 4 5 6 0 6 7 1 5 4 3 2 4 0 9 5 5 9 0 4 7 6 3 8 0 8 9 9\n",
      " 0 5 3 2 3 9 9 2 7 2 2 1 8 2 7 1 3 4 6 3 8 3 8 4 1 8 5 0 6 5 5 0 8 3 9 5 9\n",
      " 2 5 9 6 9 5 1 6 2 3 8 8 6 9 0 4 5 9 4 3 0 4 7 0 3 0 3 3 1 6 8 3 2 3 1 9 4\n",
      " 3 0 6 5 5 0 3 8 2 1 9 0 8 5 6 6 8 3 8 8 7 1 6 8 7 7 8 4 0 2 6 5 0 5 4 6 2\n",
      " 7 1 6 7 3 1 6 8 5 6 5 1 6 5 6 2 3 1 2 2 3 3 2 7 9 6 0 7 4 5 4 4 5 1 9 2 1\n",
      " 8 1 4 9 1 8 0 6 0 3 7 0 8 2 3 1 1 4 8 2 1 4 1 6 7 3 1 0 7 3 6 9 7 7 8 8 0\n",
      " 3 1 7 7 0 6 3 0 6 8 1 9 9 8 0 9 2 4 0 6 2 9 1 3 8 9 6 2 2 5 3 5 6 6 0 1 4\n",
      " 1 2 1 5 8 5 6 0 0 4 5 3 7 1 5 7 8 5 5 7 5 3 8 2 5 1 7 7 3 0 0 4 6 8 2 1 6\n",
      " 4 8 2 7 6 3 6 5 2 0 4 4 9 5 7 0 0 6 9 5 8 9 7 9 3 7 8 6 4 0 2 2 0 1 3 7 3\n",
      " 5 5 6 4 2 1 5 1 2 6 3 3 5 1 3 1 5 0 9 3 6 2 1 3 1 2 0 8 3 5 4 9 0 8 3 1 6\n",
      " 4 2 3 0 1 2 8 8 3 8 8 5 0 5 2 6 7 8 3 4 6 8 6 3 3 8 1 8 1 9 5 0 0 9 4 0 3\n",
      " 0 6 4 6 3 3 4 7 8 0 2 3 0 8 5 7 3 0 6 9 5 5 7 3 8 1 7 6 0 1 3 2 1 6 9 7 7\n",
      " 8 1 7 4 6 3 8 1 8 1 6 9 7 4 8 3 1 5 2 2 3 8 8 6 7 1 0 8 9 3 9 5 0 0 7 7 7\n",
      " 7 7 7 6 3 0 9 2 5 8 7 1 2 8 7 8 4 9 7 5 6 4 5 5 7 3 5 8 0 0 5 4 5 7 5 1 2\n",
      " 4]\n",
      "0.617\n",
      "Acc 0.6170000433921814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import jax.numpy as jnp\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_ckn_tr)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y, test_size=0.2, random_state=42)\n",
    "\n",
    "C = 1\n",
    "clf = svm.SVC(C=C, kernel='rbf', verbose=True)\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "# Make predictions on the validation data\n",
    "y_pred = clf.predict(X_val)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(accuracy)\n",
    "print(f'Acc {jnp.mean( y_pred == y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  kernelchallenge.classifiers.svm import MultiClassKernelSVM\n",
    "from kernelchallenge.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function fit took 181.83 seconds\n",
      "Function predict took 8.90 seconds\n",
      "Acc 0.65400004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kernel_func = RBF(sigma=jnp.sqrt(X_train.shape[1]))\n",
    "my_svm = MultiClassKernelSVM(num_classes=10, kernel_func=kernel_func, c=1)\n",
    "my_svm.fit(X_train, y_train)\n",
    "preds = my_svm.predict(X_val)\n",
    "\n",
    "print('Acc', jnp.mean(preds == y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 3 8 6 9 9 9 6 2 2 8 1 0 7 6 1 2 4 4 0 8 5 0 6 1 0 9 7 8 2 0 6 3 6 8 5\n",
      " 5 5 0 6 4 4 6 9 0 2 7 8 5 8 9 1 3 6 1 7 2 0 8 5 6 8 0 5 9 3 2 1 2 7 2 4 8\n",
      " 2 5 3 5 5 6 1 9 2 9 1 6 8 8 3 3 2 6 7 8 8 4 8 0 8 9 8 4 8 7 3 6 9 1 1 5 5\n",
      " 1 9 2 9 7 5 4 9 7 9 5 6 1 5 6 5 7 3 1 6 8 6 6 6 4 4 9 2 7 2 6 0 7 8 6 5 1\n",
      " 1 7 1 6 2 2 7 9 4 9 9 9 0 9 7 0 6 1 9 9 4 8 9 8 9 7 4 6 1 4 0 3 5 4 6 9 5\n",
      " 9 4 6 4 2 4 3 9 1 6 9 6 8 2 7 9 9 4 9 0 9 6 6 5 1 7 1 3 0 9 4 8 6 5 8 0 0\n",
      " 9 2 6 5 6 0 1 3 0 3 7 0 9 9 7 7 2 5 1 3 9 2 0 8 2 9 0 0 3 8 0 1 0 6 4 9 4\n",
      " 3 6 9 6 5 8 1 5 1 5 8 9 3 8 7 6 3 6 8 6 8 6 8 9 0 0 0 0 7 9 5 2 2 3 9 8 1\n",
      " 3 6 1 1 4 8 9 4 1 9 5 8 6 6 1 3 4 0 0 3 6 7 4 0 5 9 6 2 1 6 2 1 4 1 8 9 6\n",
      " 6 6 8 7 8 9 3 5 1 0 6 9 9 2 7 1 1 6 4 7 5 0 3 4 4 2 8 5 4 6 4 1 7 0 6 2 9\n",
      " 9 7 1 7 3 4 0 2 1 0 4 2 0 8 3 0 8 6 6 1 4 7 0 9 3 8 9 4 5 1 1 4 2 8 0 5 1\n",
      " 7 2 3 9 2 5 4 0 6 1 4 8 3 4 6 8 0 2 7 2 8 3 9 4 2 8 2 7 9 4 4 6 2 4 4 0 6\n",
      " 4 5 6 7 8 2 0 1 5 0 4 1 1 8 9 7 9 9 0 5 6 2 8 9 8 5 8 1 9 6 9 3 6 8 8 3 9\n",
      " 4 2 3 4 6 3 3 9 0 9 4 5 6 0 6 7 1 5 4 3 2 4 0 9 5 5 9 0 4 5 6 6 8 0 8 9 9\n",
      " 0 5 5 2 5 9 9 2 7 2 2 1 8 6 7 1 3 7 6 3 8 3 8 4 6 5 5 0 6 5 5 0 8 3 9 5 9\n",
      " 3 5 9 6 9 5 1 6 2 3 8 8 1 7 9 4 5 9 7 6 6 4 7 1 9 0 9 3 1 6 8 7 5 4 1 9 7\n",
      " 6 0 6 5 3 0 3 8 2 1 5 0 8 5 5 6 8 0 8 8 7 9 6 8 7 7 8 4 0 2 6 6 0 5 4 6 2\n",
      " 4 1 6 7 8 1 6 8 5 6 5 1 6 5 6 2 3 7 1 1 3 9 4 7 9 6 0 7 4 7 4 4 5 1 9 4 1\n",
      " 7 1 4 0 1 8 0 6 0 4 7 0 8 2 6 1 1 6 8 2 1 4 1 6 7 9 1 0 7 3 6 9 7 7 8 0 0\n",
      " 4 9 7 9 0 6 3 7 6 8 1 9 9 8 0 9 2 4 0 6 2 9 1 3 8 9 6 2 2 5 4 5 6 6 1 1 6\n",
      " 1 2 9 5 8 6 6 0 0 4 5 4 7 6 5 7 8 5 5 7 5 6 8 2 5 9 7 7 6 0 0 4 6 8 7 1 6\n",
      " 7 8 2 7 6 5 1 5 2 0 4 7 9 5 7 0 0 6 9 2 8 9 7 9 3 7 8 6 4 0 2 2 2 1 3 9 3\n",
      " 5 5 1 8 2 1 5 1 3 6 3 3 5 1 2 6 2 8 9 5 6 8 1 1 1 2 0 8 3 5 4 9 0 8 6 1 7\n",
      " 4 0 3 0 1 2 8 8 3 8 8 3 0 5 2 6 7 8 5 4 2 8 4 3 3 8 1 8 1 9 5 0 0 9 4 0 3\n",
      " 0 6 4 6 3 2 4 9 4 0 2 4 0 9 2 7 3 0 6 9 5 5 7 4 8 1 7 6 0 1 8 2 1 6 9 7 7\n",
      " 8 0 7 4 6 4 8 1 8 1 6 9 7 4 8 3 1 5 2 2 3 8 1 6 7 1 0 8 9 9 9 5 9 0 7 7 7\n",
      " 7 7 7 6 3 1 9 2 5 8 7 1 2 8 7 8 4 9 7 6 6 4 4 5 7 3 5 8 0 0 5 4 5 7 4 1 4\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
