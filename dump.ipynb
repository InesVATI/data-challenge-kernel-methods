{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import numbers\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from utils.utils_fast import conv2\n",
    "import pickle\n",
    "import utils.load_data import load_data\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred(y_pred, outpath=\"output/\"):\n",
    "    ids = np.arange(1, 2001, dtype=int)\n",
    "    arr = np.hstack((ids.reshape(-1, 1), y_pred.reshape(-1, 1)))\n",
    "    arr = arr.astype(int)\n",
    "    np.savetxt(\n",
    "        outpath + \"Yte.csv\",\n",
    "        arr,\n",
    "        header=\"Id,Prediction\",\n",
    "        fmt=\"%d,%d\",\n",
    "        delimiter=\",\",\n",
    "        comments=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def reshape(images, sx=32, n_channels=3):\n",
    "    return images.reshape((-1, n_channels, sx, sx)).swapaxes(1, 2).swapaxes(2, 3)\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"visualize image of given vec: 1 x 3072\"\"\"\n",
    "    if img.ndim < 3:\n",
    "        print(\"ok\")\n",
    "        img = img.reshape((32, 32, 3), order=\"F\")\n",
    "        img = img.swapaxes(0, 1)\n",
    "    for i in range(3):\n",
    "        minval = img[:, :, i].min()\n",
    "        maxval = img[:, :, i].max()\n",
    "        if minval != maxval:\n",
    "            img[:, :, i] -= minval\n",
    "            img[:, :, i] *= 1.0 / (maxval - minval)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def distribution_y(filepath=\"data/\"):\n",
    "    y = np.genfromtxt(filepath + \"Ytr.csv\", delimiter=\",\", skip_header=1, dtype=int)[\n",
    "        :, -1\n",
    "    ]\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(y)\n",
    "    vmin = y.min()\n",
    "    vmax = y.max()\n",
    "    plt.hist(y, bins=np.arange(vmin - 0.5, vmax + 1.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_random_state(seed):\n",
    "    \"\"\"Turn seed into a np.random.RandomState instance\n",
    "    If seed is None, return the RandomState singleton used by np.random.\n",
    "    If seed is an int, return a new RandomState instance seeded with seed.\n",
    "    If seed is already a RandomState instance, return it.\n",
    "    Otherwise raise ValueError.\n",
    "    \"\"\"\n",
    "    if seed is None or seed is np.random:\n",
    "        return np.random.mtrand._rand\n",
    "    if isinstance(seed, (numbers.Integral, np.integer)):\n",
    "        return np.random.RandomState(seed)\n",
    "    if isinstance(seed, np.random.RandomState):\n",
    "        return seed\n",
    "    raise ValueError(\n",
    "        \"%r cannot be used to seed a numpy.random.RandomState\" \" instance\" % seed\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_patches_2d(image, patch_size, step=1):\n",
    "    \"\"\"image : nx x ny x n_channels\n",
    "    output: n_patches x patch_size x patch_size x n_channels\n",
    "    \"\"\"\n",
    "    n_channels = image.shape[-1]\n",
    "    patches = extract_patches(image, (patch_size, patch_size, n_channels), step)\n",
    "    return patches.reshape(-1, patch_size, patch_size, n_channels)\n",
    "\n",
    "\n",
    "def extract_patches(arr, patch_shape, extraction_step):\n",
    "    if isinstance(extraction_step, int):\n",
    "        extraction_step = tuple([extraction_step] * arr.ndim)\n",
    "    patch_strides = arr.strides\n",
    "    slices = tuple(slice(None, None, st) for st in extraction_step)\n",
    "    # print(slices, type(arr), arr)\n",
    "    # slices\n",
    "    indexing_strides = arr[slices].strides\n",
    "\n",
    "    patch_indices_shape = (\n",
    "        (np.array(arr.shape) - np.array(patch_shape)) // np.array(extraction_step)\n",
    "    ) + 1\n",
    "\n",
    "    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n",
    "    strides = tuple(list(indexing_strides) + list(patch_strides))\n",
    "\n",
    "    patches = as_strided(arr, shape=shape, strides=strides)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def centering_patch(patch):\n",
    "    return patch - np.mean(patch, axis=(1, 2), keepdims=1)\n",
    "\n",
    "\n",
    "def shape_patch(patch, threshold=1e-6):\n",
    "    \"\"\"patch: n_patches x size x size x n_channels\n",
    "    output: n_patches x (size^2-1)n_channels\n",
    "    \"\"\"\n",
    "    n_channels = patch.shape[-1]\n",
    "    patch = patch.reshape((patch.shape[0], -1, patch.shape[-1]))\n",
    "    center = int(patch.shape[1] // 2)\n",
    "    patch = patch - patch[:, [center], :]\n",
    "    patch = np.delete(patch, center, 1)  # remove center\n",
    "    patch = patch.reshape((patch.shape[0], -1))\n",
    "    # rho = np.linalg.norm(patch, axis=1)\n",
    "    # rho[rho<threshold] = 0\n",
    "    # # binarize the difference\n",
    "    # cond = patch > 0\n",
    "    # non_cond = patch <= 0\n",
    "    # patch[cond] = 1.0\n",
    "    # patch[non_cond] = 0.0\n",
    "    return patch\n",
    "\n",
    "\n",
    "def normalize_row(X, norm=\"l2\", threshold=1e-5, return_norm=False):\n",
    "    if norm == \"l2\":\n",
    "        norms = np.linalg.norm(X, axis=1)\n",
    "        norms[norms < threshold] = threshold\n",
    "        X /= norms[:, np.newaxis]\n",
    "    if return_norm:\n",
    "        return X, norms\n",
    "    return X\n",
    "\n",
    "\n",
    "def kmeans(X, k, max_iter=1000, init=None):\n",
    "    \"\"\"normal kmeans\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    if init is None:\n",
    "        perm = np.random.choice(np.arange(n_samples), k)\n",
    "        centroids = X[perm]\n",
    "\n",
    "    norm2 = np.linalg.norm(X, axis=1, keepdims=1) ** 2\n",
    "    prev_obj = np.inf\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        dist2 = (\n",
    "            np.linalg.norm(centroids, axis=1) ** 2\n",
    "            - 2.0 * np.dot(X, centroids.T)\n",
    "            + norm2\n",
    "        )\n",
    "        assign = np.argmin(dist2, axis=1)\n",
    "        obj = dist2[np.unravel_index(assign, dist2.shape)].mean()\n",
    "        # print dist.shape\n",
    "        if (n_iter + 1) % 10 == 0:\n",
    "            print((\"kmeans iter %d, objective: %f\" % (n_iter + 1, obj)))\n",
    "\n",
    "        for j in range(k):\n",
    "            Xj = X[assign == j]\n",
    "            if Xj.shape[0] == 0:\n",
    "                centroids[j] = X[np.random.randint(n_samples)]\n",
    "            else:\n",
    "                centroids[j] = np.mean(Xj, axis=0)\n",
    "\n",
    "        if np.abs(prev_obj - obj) / (np.abs(obj) + 1e-20) < 1e-8:\n",
    "            break\n",
    "        prev_obj = obj\n",
    "\n",
    "        # stop criteria\n",
    "    return centroids, assign\n",
    "\n",
    "\n",
    "def spherical_kmeans(X, k, max_iter=1000, init=None):\n",
    "    \"\"\"X: n x d points with unit-norm\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    if init is None:\n",
    "        perm = np.random.choice(np.arange(n_samples), k)\n",
    "        centroids = X[perm]\n",
    "\n",
    "    prev_obj = np.inf\n",
    "    for n_iter in range(max_iter):\n",
    "        cos_sim = np.dot(X, centroids.T)\n",
    "        assign = np.argmax(cos_sim, axis=1)\n",
    "        obj = cos_sim[np.unravel_index(assign, cos_sim.shape)].mean()\n",
    "\n",
    "        if (n_iter + 1) % 10 == 0:\n",
    "            print((\"spherical kmeans iter %d, objective: %f\" % (n_iter + 1, obj)))\n",
    "\n",
    "        for j in range(k):\n",
    "            Xj = X[assign == j]\n",
    "            if Xj.shape[0] == 0:\n",
    "                centroids[j] = X[np.random.randint(n_samples)]\n",
    "            else:\n",
    "                centroids[j] = np.sum(Xj, axis=0)\n",
    "                norm = np.linalg.norm(centroids[j])\n",
    "                centroids[j] /= norm\n",
    "        if np.abs(prev_obj - obj) / (np.abs(obj) + 1e-20) < 1e-8:\n",
    "            break\n",
    "        prev_obj = obj\n",
    "\n",
    "    return centroids, assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_1d(shape, sigma):\n",
    "    m = (shape - 1.0) / 2.0\n",
    "    filt = np.arange(-m, m + 1)\n",
    "    filt = np.exp(-np.square(filt) / (2.0 * sigma**2))\n",
    "    return filt / np.sum(filt)\n",
    "\n",
    "\n",
    "def conv2_gaussian(in1, shape, sigma=0.5):\n",
    "    g_filter = gaussian_filter_1d(shape, sigma)\n",
    "    g_filter = np.outer(g_filter, g_filter)\n",
    "    return conv2(in1, g_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERTYPES = [\"gradient\", \"patch\", \"shape\"]\n",
    "\n",
    "\n",
    "class CKN(object):\n",
    "    \"\"\"docstring for CKN\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_sizes=[1, 2],\n",
    "        subsamplings=[2, 4],\n",
    "        map_dims={12, 200},\n",
    "        layer_type=\"gradient\",\n",
    "    ):\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.subsamplings = subsamplings\n",
    "        self.map_dims = map_dims\n",
    "        if layer_type in LAYERTYPES:\n",
    "            self.layer_type = layer_type\n",
    "        else:\n",
    "            raise ValueError(\"unknown layer type\")\n",
    "        self.n_layers = len(patch_sizes)\n",
    "\n",
    "    def train(self, images):\n",
    "        \"\"\"\n",
    "        images: n x sx x sx x channels\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        psis = images\n",
    "        n = images.shape[0]\n",
    "        for i in range(self.n_layers):\n",
    "            centering = (i == 0) and (self.layer_type == \"patch\")\n",
    "            layer = CKNLayer(\n",
    "                i,\n",
    "                centering,\n",
    "                self.layer_type,\n",
    "                self.patch_sizes[i],\n",
    "                self.map_dims[i],\n",
    "                self.subsamplings[i],\n",
    "            )\n",
    "\n",
    "            layer.train(psis)\n",
    "\n",
    "            self.layers.append(layer)\n",
    "            if i < self.n_layers - 1:\n",
    "                for j in range(n):\n",
    "                    psi = layer.forward(psis[j])\n",
    "                    if j == 0:\n",
    "                        out_psis = np.zeros((n,) + psi.shape)\n",
    "                    out_psis[j] = psi\n",
    "                psis = out_psis\n",
    "\n",
    "    def forward(self, image, layer=None):\n",
    "        \"\"\"output map of the i-th layer\n",
    "        layer: int < n_layers\n",
    "        image: sx x sx x channels\n",
    "        \"\"\"\n",
    "        if layer is None:\n",
    "            layer = self.n_layers\n",
    "        psi = image\n",
    "        for i in range(layer):\n",
    "            psi = self.layers[i].forward(psi)\n",
    "        return psi\n",
    "\n",
    "    def out_maps(self, images):\n",
    "        n = images.shape[0]\n",
    "        for i in range(n):\n",
    "            output_map = self.forward(images[i])\n",
    "            output_map = output_map.flatten()\n",
    "            if i == 0:\n",
    "                res = np.zeros((n, output_map.shape[0]))\n",
    "            res[i] = output_map\n",
    "        return res\n",
    "\n",
    "\n",
    "def save(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "class CKNLayer(object):\n",
    "    def __init__(self, order, centering, layer_type, patch_size, map_dim, subsampling):\n",
    "        self.order = order\n",
    "        self.centering = centering\n",
    "        self.layer_type = layer_type\n",
    "        self.patch_size = patch_size\n",
    "        self.map_dim = map_dim\n",
    "        self.subsampling = subsampling\n",
    "        self.n_patches_per_image = 10\n",
    "\n",
    "    def train(self, input_maps):\n",
    "        if self.order == 0 and self.layer_type == \"gradient\":\n",
    "            # no parameter training for gradient map\n",
    "            return\n",
    "        elif self.order == 0 and self.layer_type == \"shape\":\n",
    "            n = input_maps.shape[0]\n",
    "            for i in range(n):\n",
    "                psi = input_maps[i]\n",
    "                patch = extract_patches_2d(psi, self.patch_size)\n",
    "\n",
    "                patch = shape_patch(patch)\n",
    "                if i == 0:\n",
    "                    n_patches_per_image = np.minimum(\n",
    "                        2 * self.n_patches_per_image, patch.shape[0]\n",
    "                    )\n",
    "                    X = np.zeros((n * n_patches_per_image, patch.shape[1]))\n",
    "                # discard patches with no variance\n",
    "                idx = np.any(patch != patch[:, [0]], axis=1)\n",
    "                if n_patches_per_image <= idx.sum():\n",
    "                    patch = patch[idx]\n",
    "                np.random.shuffle(patch)\n",
    "                X[i * n_patches_per_image : (i + 1) * n_patches_per_image] = patch[\n",
    "                    :n_patches_per_image\n",
    "                ]\n",
    "            np.random.shuffle(X)\n",
    "            X = normalize_row(X, norm=\"l2\")\n",
    "            Z = spherical_kmeans(X, self.map_dim)[0]\n",
    "            self.Z = Z\n",
    "            self.sigma2 = 0.25\n",
    "            lin_tran = gaussian_func(Z.dot(Z.T), self.sigma2)\n",
    "            # svd decomposition to compute lin_tran^(-0.5)\n",
    "            w, v = np.linalg.eigh(lin_tran)\n",
    "            w = (w + 1e-8) ** (-0.5)\n",
    "            lin_tran = v.dot(np.diag(w).dot(v.T))\n",
    "            self.lin_tran = lin_tran\n",
    "        else:\n",
    "            n = input_maps.shape[0]\n",
    "            for i in range(n):\n",
    "                psi = input_maps[i]\n",
    "                patch = extract_patches_2d(psi, self.patch_size)\n",
    "                if self.centering:\n",
    "                    patch = centering_patch(patch)\n",
    "                # print patch.shape\n",
    "                patch = patch.reshape((patch.shape[0], -1))\n",
    "                if i == 0:\n",
    "                    n_patches_per_image = np.minimum(\n",
    "                        2 * self.n_patches_per_image, patch.shape[0]\n",
    "                    )\n",
    "                    X = np.zeros((n * n_patches_per_image, patch.shape[1]))\n",
    "                # discard patches with no variance\n",
    "                idx = np.any(patch != patch[:, [0]], axis=1)\n",
    "                if n_patches_per_image <= idx.sum():\n",
    "                    patch = patch[idx]\n",
    "                np.random.shuffle(patch)\n",
    "                X[i * n_patches_per_image : (i + 1) * n_patches_per_image] = patch[\n",
    "                    :n_patches_per_image\n",
    "                ]\n",
    "            np.random.shuffle(X)\n",
    "            X = normalize_row(X, norm=\"l2\")\n",
    "            Z = spherical_kmeans(X, self.map_dim)[0]\n",
    "            self.Z = Z\n",
    "            self.sigma2 = 0.25\n",
    "            lin_tran = gaussian_func(Z.dot(Z.T), self.sigma2)\n",
    "            # svd decomposition to compute lin_tran^(-0.5)\n",
    "            w, v = np.linalg.eigh(lin_tran)\n",
    "            w = (w + 1e-8) ** (-0.5)\n",
    "            lin_tran = v.dot(np.diag(w).dot(v.T))\n",
    "            self.lin_tran = lin_tran\n",
    "\n",
    "    def forward(self, input_map):\n",
    "        if self.order == 0 and self.layer_type == \"gradient\":\n",
    "            n_channels = input_map.shape[-1]\n",
    "            output_map = np.zeros(input_map.shape[:-1] + (self.map_dim * n_channels,))\n",
    "            theta = np.linspace(0, 2.0 * np.pi, self.map_dim + 1)[:-1]\n",
    "            delta_theta = 2.0 * np.pi / self.map_dim\n",
    "            sigma2 = np.square(1 - np.cos(delta_theta)) + np.square(np.sin(delta_theta))\n",
    "            self.sigma2 = sigma2\n",
    "            for k in range(n_channels):\n",
    "                input_map_k = input_map[:, :, k]\n",
    "                dx, dy = np.gradient(input_map_k)\n",
    "                rho = np.sqrt(np.square(dx) + np.square(dy))\n",
    "                idx = rho > 0\n",
    "                dx[idx] = dx[idx] / rho[idx]\n",
    "                dy[idx] = dy[idx] / rho[idx]\n",
    "                # sample theta between [0, 2*pi]\n",
    "                for i in range(self.map_dim):\n",
    "                    output_map[:, :, i + self.map_dim * k] = rho * gaussian_func(\n",
    "                        dx * np.cos(theta[i]) + dy * np.sin(theta[i]), sigma2\n",
    "                    )\n",
    "        elif self.order == 0 and self.layer_type == \"shape\":\n",
    "            # we suppose that patch_size is odd\n",
    "            n_channels = input_map.shape[-1]\n",
    "            patch = extract_patches_2d(input_map, self.patch_size)\n",
    "            size = input_map.shape[0] - self.patch_size + 1\n",
    "            patch = shape_patch(patch)\n",
    "            patch, rho = normalize_row(patch, norm=\"l2\", return_norm=True)\n",
    "\n",
    "            output_map = gaussian_func(patch.dot(self.Z.T), self.sigma2)\n",
    "            output_map = np.diag(rho).dot(output_map.dot(self.lin_tran))\n",
    "            output_map = output_map.reshape((size, size, -1))\n",
    "        else:\n",
    "            patch = extract_patches_2d(input_map, self.patch_size)\n",
    "            size = input_map.shape[0] - self.patch_size + 1\n",
    "            # centering\n",
    "            if self.centering:\n",
    "                patch = centering_patch(patch)\n",
    "\n",
    "            patch = patch.reshape((patch.shape[0], -1))\n",
    "\n",
    "            patch, rho = normalize_row(patch, norm=\"l2\", return_norm=True)\n",
    "            output_map = gaussian_func(patch.dot(self.Z.T), self.sigma2)\n",
    "            output_map = np.diag(rho).dot(output_map.dot(self.lin_tran))\n",
    "            output_map = output_map.reshape((size, size, -1))\n",
    "\n",
    "        # gaussian smoothing\n",
    "        for i in range(output_map.shape[-1]):\n",
    "            output_map[:, :, i] = conv2_gaussian(\n",
    "                output_map[:, :, i],\n",
    "                2 * self.subsampling + 1,\n",
    "                self.subsampling / np.sqrt(2),\n",
    "            )\n",
    "        output_map = output_map[\n",
    "            int((self.subsampling - 1) // 2) :: self.subsampling,\n",
    "            int((self.subsampling - 1) // 2) :: self.subsampling,\n",
    "            :,\n",
    "        ]\n",
    "        return output_map\n",
    "\n",
    "\n",
    "def gaussian_func(x, sigma2):\n",
    "    return np.exp(1 / sigma2 * (x - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "data_path = os.path.join(current_path, \"data\")\n",
    "# data_folder =\n",
    "X, y, X_test = utils.load_data(data_folder=data_path)\n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spherical kmeans iter 10, objective: 0.736805\n",
      "spherical kmeans iter 20, objective: 0.736147\n",
      "spherical kmeans iter 30, objective: 0.736058\n",
      "spherical kmeans iter 40, objective: 0.735939\n",
      "spherical kmeans iter 50, objective: 0.735849\n",
      "spherical kmeans iter 60, objective: 0.735817\n",
      "spherical kmeans iter 70, objective: 0.735804\n",
      "spherical kmeans iter 80, objective: 0.735813\n",
      "spherical kmeans iter 90, objective: 0.735761\n",
      "spherical kmeans iter 100, objective: 0.735751\n",
      "spherical kmeans iter 110, objective: 0.735755\n",
      "spherical kmeans iter 120, objective: 0.735751\n",
      "spherical kmeans iter 130, objective: 0.735738\n",
      "spherical kmeans iter 140, objective: 0.735740\n",
      "spherical kmeans iter 150, objective: 0.735740\n",
      "spherical kmeans iter 160, objective: 0.735745\n",
      "spherical kmeans iter 170, objective: 0.735737\n",
      "spherical kmeans iter 180, objective: 0.735733\n",
      "spherical kmeans iter 190, objective: 0.735737\n",
      "ckn training time: 55.30 s\n",
      "spherical kmeans iter 10, objective: 0.000342\n",
      "spherical kmeans iter 20, objective: 0.000962\n",
      "spherical kmeans iter 30, objective: 0.000577\n",
      "spherical kmeans iter 40, objective: 0.000972\n",
      "spherical kmeans iter 50, objective: 0.001066\n",
      "spherical kmeans iter 60, objective: 0.000936\n",
      "spherical kmeans iter 70, objective: 0.001038\n",
      "spherical kmeans iter 80, objective: 0.001056\n",
      "spherical kmeans iter 90, objective: 0.001042\n",
      "spherical kmeans iter 100, objective: 0.001050\n",
      "spherical kmeans iter 110, objective: 0.001141\n",
      "spherical kmeans iter 120, objective: 0.001099\n",
      "spherical kmeans iter 130, objective: 0.001042\n",
      "spherical kmeans iter 140, objective: 0.001130\n",
      "spherical kmeans iter 150, objective: 0.001106\n",
      "spherical kmeans iter 160, objective: 0.001067\n",
      "spherical kmeans iter 170, objective: 0.001034\n",
      "spherical kmeans iter 180, objective: 0.001076\n",
      "spherical kmeans iter 190, objective: 0.001084\n",
      "spherical kmeans iter 10, objective: 0.399869\n",
      "spherical kmeans iter 20, objective: 0.399116\n",
      "spherical kmeans iter 30, objective: 0.398789\n",
      "spherical kmeans iter 40, objective: 0.398699\n",
      "spherical kmeans iter 50, objective: 0.398660\n",
      "spherical kmeans iter 60, objective: 0.398650\n",
      "spherical kmeans iter 70, objective: 0.398643\n",
      "spherical kmeans iter 80, objective: 0.398593\n",
      "spherical kmeans iter 90, objective: 0.398583\n",
      "spherical kmeans iter 100, objective: 0.398583\n",
      "spherical kmeans iter 110, objective: 0.398558\n",
      "spherical kmeans iter 120, objective: 0.398563\n",
      "spherical kmeans iter 130, objective: 0.398559\n",
      "spherical kmeans iter 140, objective: 0.398565\n",
      "spherical kmeans iter 150, objective: 0.398553\n",
      "spherical kmeans iter 160, objective: 0.398554\n",
      "spherical kmeans iter 170, objective: 0.398545\n",
      "spherical kmeans iter 180, objective: 0.398544\n",
      "ckn training time: 162.99 s\n",
      "spherical kmeans iter 10, objective: 0.001219\n",
      "spherical kmeans iter 20, objective: 0.000937\n",
      "spherical kmeans iter 30, objective: 0.000834\n",
      "spherical kmeans iter 40, objective: 0.000878\n",
      "spherical kmeans iter 50, objective: 0.000946\n",
      "spherical kmeans iter 60, objective: 0.000906\n",
      "spherical kmeans iter 70, objective: 0.000914\n",
      "spherical kmeans iter 80, objective: 0.000946\n",
      "spherical kmeans iter 90, objective: 0.000889\n",
      "spherical kmeans iter 100, objective: 0.000933\n",
      "spherical kmeans iter 110, objective: 0.000902\n",
      "spherical kmeans iter 120, objective: 0.000929\n",
      "spherical kmeans iter 130, objective: 0.000928\n",
      "spherical kmeans iter 140, objective: 0.000940\n",
      "spherical kmeans iter 150, objective: 0.000939\n",
      "spherical kmeans iter 160, objective: 0.000928\n",
      "ckn training time: 33.72 s\n",
      "(5000, 8200)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "train = True\n",
    "save_model = False\n",
    "prediction = False\n",
    "save_svm_model = False\n",
    "\n",
    "\n",
    "model1 = CKN([1, 2], [2, 4], [12, 200], \"gradient\")\n",
    "model2 = CKN([2, 2], [2, 4], [100, 200], \"patch\")\n",
    "model3 = CKN([3], [10], [200], \"patch\")\n",
    "# model4 = CKN([3, 2], [2, 4], [100, 200], 'shape')\n",
    "models = [model1, model2, model3]\n",
    "\n",
    "norms = []\n",
    "X_ckn_tr = []\n",
    "for i, model in enumerate(models):\n",
    "    if train:\n",
    "        tic = time.time()\n",
    "        model.train(X)\n",
    "        toc = time.time()\n",
    "        print((\"ckn training time: %.2f s\" % (toc - tic)))\n",
    "        if save_model:\n",
    "            save(model, \"model/\" + model.layer_type + \"_\" + str(model.n_layers))\n",
    "    else:\n",
    "        model = load(\"model/\" + model.layer_type + \"_\" + str(model.n_layers))\n",
    "        models[i] = model\n",
    "    X_ckn = model.out_maps(X)\n",
    "    X_ckn = X_ckn - X_ckn.mean(axis=1, keepdims=1)\n",
    "    norm = np.mean(np.sqrt(np.sum(np.square(X_ckn), axis=1)))\n",
    "    X_ckn = X_ckn / norm\n",
    "    norms.append(norm)\n",
    "    X_ckn_tr.append(X_ckn)\n",
    "\n",
    "X_ckn_tr = np.hstack(X_ckn_tr)\n",
    "del X\n",
    "del X_ckn\n",
    "\n",
    "print(X_ckn_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training in unsupervised we can do the testing afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_ckn_tr)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]*\n",
      "optimization finished, #iter = 787\n",
      "obj = -188.997480, rho = 0.239769\n",
      "nSV = 521, nBSV = 154\n",
      "*\n",
      "optimization finished, #iter = 719\n",
      "obj = -236.557886, rho = -0.280691\n",
      "nSV = 516, nBSV = 225\n",
      "*\n",
      "optimization finished, #iter = 655\n",
      "obj = -185.034444, rho = -0.332693\n",
      "nSV = 450, nBSV = 161\n",
      "*\n",
      "optimization finished, #iter = 625\n",
      "obj = -180.664184, rho = -0.659556\n",
      "nSV = 429, nBSV = 166\n",
      "*\n",
      "optimization finished, #iter = 575\n",
      "obj = -144.635054, rho = -0.272566\n",
      "nSV = 376, nBSV = 122\n",
      "*\n",
      "optimization finished, #iter = 592\n",
      "obj = -132.351344, rho = -0.286710\n",
      "nSV = 374, nBSV = 101\n",
      "*\n",
      "optimization finished, #iter = 629\n",
      "obj = -152.606246, rho = -0.280731\n",
      "nSV = 403, nBSV = 126\n",
      "*.*\n",
      "optimization finished, #iter = 882\n",
      "obj = -292.028856, rho = -0.341094\n",
      "nSV = 626, nBSV = 293\n",
      "*\n",
      "optimization finished, #iter = 682\n",
      "obj = -165.947291, rho = 0.161166\n",
      "nSV = 448, nBSV = 137\n",
      "*\n",
      "optimization finished, #iter = 682\n",
      "obj = -132.189840, rho = -0.490025\n",
      "nSV = 418, nBSV = 93\n",
      "*\n",
      "optimization finished, #iter = 643\n",
      "obj = -135.577950, rho = -0.593865\n",
      "nSV = 418, nBSV = 103\n",
      "*\n",
      "optimization finished, #iter = 603\n",
      "obj = -113.822186, rho = -0.717597\n",
      "nSV = 374, nBSV = 80\n",
      "*\n",
      "optimization finished, #iter = 597\n",
      "obj = -107.340345, rho = -0.618063\n",
      "nSV = 367, nBSV = 70\n",
      "*\n",
      "optimization finished, #iter = 609\n",
      "obj = -123.792565, rho = -0.525577\n",
      "nSV = 388, nBSV = 91\n",
      "*\n",
      "optimization finished, #iter = 661\n",
      "obj = -128.103168, rho = -0.508231\n",
      "nSV = 403, nBSV = 81\n",
      "*.*\n",
      "optimization finished, #iter = 821\n",
      "obj = -197.350764, rho = -0.573866\n",
      "nSV = 544, nBSV = 168\n",
      "*.*\n",
      "optimization finished, #iter = 872\n",
      "obj = -225.040497, rho = -0.123333\n",
      "nSV = 588, nBSV = 192\n",
      "*\n",
      "optimization finished, #iter = 787\n",
      "obj = -314.986022, rho = -0.234085\n",
      "nSV = 626, nBSV = 331\n",
      "*\n",
      "optimization finished, #iter = 784\n",
      "obj = -300.023937, rho = -0.570861\n",
      "nSV = 597, nBSV = 313\n",
      "*\n",
      "optimization finished, #iter = 770\n",
      "obj = -288.243911, rho = -0.208950\n",
      "nSV = 590, nBSV = 293\n",
      "*\n",
      "optimization finished, #iter = 671\n",
      "obj = -233.071490, rho = -0.118681\n",
      "nSV = 492, nBSV = 226\n",
      "*\n",
      "optimization finished, #iter = 756\n",
      "obj = -238.764544, rho = -0.147414\n",
      "nSV = 545, nBSV = 228\n",
      "*\n",
      "optimization finished, #iter = 636\n",
      "obj = -164.226663, rho = 0.000564\n",
      "nSV = 423, nBSV = 153\n",
      "*\n",
      "optimization finished, #iter = 692\n",
      "obj = -136.427675, rho = 0.318084\n",
      "nSV = 434, nBSV = 97\n",
      "*\n",
      "optimization finished, #iter = 775\n",
      "obj = -288.560135, rho = -0.535386\n",
      "nSV = 596, nBSV = 299\n",
      "*\n",
      "optimization finished, #iter = 805\n",
      "obj = -379.826941, rho = 0.077305\n",
      "nSV = 683, nBSV = 402\n",
      "*\n",
      "optimization finished, #iter = 701\n",
      "obj = -240.960853, rho = 0.043892\n",
      "nSV = 513, nBSV = 236\n",
      "*.*\n",
      "optimization finished, #iter = 834\n",
      "obj = -253.853066, rho = 0.114236\n",
      "nSV = 577, nBSV = 245\n",
      "*\n",
      "optimization finished, #iter = 595\n",
      "obj = -160.363787, rho = 0.079941\n",
      "nSV = 410, nBSV = 147\n",
      "*\n",
      "optimization finished, #iter = 765\n",
      "obj = -164.472477, rho = 0.391573\n",
      "nSV = 479, nBSV = 129\n",
      "*\n",
      "optimization finished, #iter = 720\n",
      "obj = -247.576268, rho = 0.439157\n",
      "nSV = 529, nBSV = 243\n",
      "*\n",
      "optimization finished, #iter = 727\n",
      "obj = -220.251173, rho = 0.420587\n",
      "nSV = 498, nBSV = 208\n",
      "*\n",
      "optimization finished, #iter = 734\n",
      "obj = -258.214340, rho = 0.439726\n",
      "nSV = 543, nBSV = 269\n",
      "*\n",
      "optimization finished, #iter = 595\n",
      "obj = -139.320255, rho = 0.318802\n",
      "nSV = 386, nBSV = 120\n",
      "*\n",
      "optimization finished, #iter = 687\n",
      "obj = -129.917464, rho = 0.595997\n",
      "nSV = 411, nBSV = 97\n",
      "*\n",
      "optimization finished, #iter = 625\n",
      "obj = -201.629566, rho = 0.017778\n",
      "nSV = 446, nBSV = 190\n",
      "*\n",
      "optimization finished, #iter = 781\n",
      "obj = -269.244082, rho = 0.173595\n",
      "nSV = 572, nBSV = 270\n",
      "*\n",
      "optimization finished, #iter = 514\n",
      "obj = -114.126028, rho = 0.029843\n",
      "nSV = 338, nBSV = 100\n",
      "*\n",
      "optimization finished, #iter = 666\n",
      "obj = -136.195194, rho = 0.400879\n",
      "nSV = 430, nBSV = 108\n",
      "*\n",
      "optimization finished, #iter = 669\n",
      "obj = -158.597264, rho = -0.009811\n",
      "nSV = 428, nBSV = 135\n",
      "*\n",
      "optimization finished, #iter = 554\n",
      "obj = -112.970383, rho = 0.041672\n",
      "nSV = 334, nBSV = 79\n",
      "*\n",
      "optimization finished, #iter = 678\n",
      "obj = -120.823038, rho = 0.321033\n",
      "nSV = 409, nBSV = 88\n",
      "*\n",
      "optimization finished, #iter = 583\n",
      "obj = -118.994261, rho = 0.043874\n",
      "nSV = 358, nBSV = 93\n",
      "*\n",
      "optimization finished, #iter = 781\n",
      "obj = -172.105600, rho = 0.351826\n",
      "nSV = 497, nBSV = 140\n",
      "*\n",
      "optimization finished, #iter = 734\n",
      "obj = -176.085929, rho = 0.402153\n",
      "nSV = 482, nBSV = 149\n",
      "Total nSV = 3736\n"
     ]
    }
   ],
   "source": [
    "C = 1\n",
    "clf = svm.SVC(C=C, kernel='rbf', verbose=True)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
